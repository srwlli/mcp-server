# CodeRef Ecosystem - The Ultimate Guide

**Document Version:** 1.0.0
**Created:** 2025-12-30
**Last Updated:** 2025-12-30
**Status:** Living Document (Discovering Features Together)
**Audience:** Human Users

---

## Meta Documentation

**Document Type:** User Guide
**Scope:** Complete CodeRef MCP ecosystem overview and capabilities discovery
**Maintenance:** Updated as we discover new features and workflows
**Related Docs:**
- `CLAUDE.md` - Technical architecture for AI agents
- `README.md` - Quick start and installation
- Individual server `CLAUDE.md` files for deep dives

---

## Purpose

**Why This Guide Exists:**

The CodeRef Ecosystem is a powerful system of 5 interconnected MCP servers that transform how AI agents plan, code, test, and document software. This guide helps you understand what's possible, how it works, and how to use it effectively.

**What Makes This Different:**

Most documentation tells you *what* tools do. This guide shows you *why* they matter and *how* they work together to solve real problems.

**Who This Is For:**
- Developers using Claude Code with MCP servers
- Teams implementing AI-assisted development workflows
- Anyone curious about intelligent code analysis and planning

---

## Overview

### What Is the CodeRef Ecosystem?

CodeRef is an integrated system of **5 MCP (Model Context Protocol) servers** that give AI agents superpowers:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CodeRef Ecosystem                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ğŸ§  coderef-context    â†’ Code Intelligence & Dependencies   â”‚
â”‚  ğŸ“‹ coderef-workflow   â†’ Planning & Orchestration           â”‚
â”‚  ğŸ“š coderef-docs       â†’ Documentation Automation           â”‚
â”‚  ğŸ­ coderef-personas   â†’ Expert Agent Specialists           â”‚
â”‚  ğŸ§ª coderef-testing    â†’ Test Automation & Coverage         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**The Problem It Solves:**

AI agents are powerful but often "code blind" - they can't see:
- What depends on what
- What breaks when you change code
- Which patterns to follow
- What's already been tested

CodeRef gives agents **X-ray vision** into your codebase.

---

## What We Discovered: The CodeRef Scan

### The Scan - Your Codebase Intelligence Engine

When you run `coderef scan`, something magical happens:

**What It Does:**
```bash
# Scan your entire project
coderef scan --project-path /path/to/project

# Result: Complete inventory of your codebase
âœ… 116,233 code elements discovered
âœ… Functions, classes, methods mapped
âœ… Dependencies graphed
âœ… Relationships traced
```

**What Gets Captured:**

For every single piece of code in your project:

| Element | What's Stored | Example |
|---------|--------------|---------|
| **Name** | Function/class identifier | `generate_plan` |
| **Type** | Element category | `function`, `class`, `method` |
| **Location** | File path + line number | `server.py:245` |
| **Visibility** | Public or private | `exported: true/false` |
| **Relationships** | What it calls/who calls it | Dependency graph |

**Example Output:**
```json
{
  "type": "function",
  "name": "generate_plan",
  "file": "C:/Users/willh/.mcp-servers/coderef-docs/generators/planning_generator.py",
  "line": 87,
  "exported": true
}
```

### Why This Matters

**Before CodeRef Scan:**
```
Developer: "Can I delete this old function?"
Response: "Let me grep the codebase... check imports... test it... hope nothing breaks..."
Time: 30-60 minutes of detective work
Risk: High - might miss hidden dependencies
```

**After CodeRef Scan:**
```
Developer: "Can I delete this old function?"
CodeRef: "No - 12 files still use it. Here's the list."
Time: 2 seconds
Risk: Zero - you know exactly what depends on it
```

---

## The Five Powers: What Each Server Does

### 1. ğŸ§  CodeRef-Context: The Code Intelligence Engine

**What It Does:**
Gives you X-ray vision into your codebase's structure and dependencies.

**Real-World Use Cases:**

**Use Case 1: "What Breaks If I Change This?"**
```bash
# You want to rename a function
coderef impact --element generatePlan --operation modify

# Returns:
Impact Analysis:
â”œâ”€ 12 files will need updates
â”œâ”€ 47 function calls affected
â”œâ”€ 3 test files need modification
â””â”€ Estimated risk: MODERATE
```

**Use Case 2: "How Did We Get Here?"**
```bash
# Trace the path from user input to database
coderef query --type shortest-path \
  --source handleUserRequest \
  --target saveToDatabase

# Returns:
Call Chain:
handleUserRequest â†’ validateInput â†’ processData â†’ saveToDatabase
```

**Use Case 3: "Is This Code Too Complex?"**
```bash
coderef complexity --element authenticateUser

# Returns:
Complexity Metrics:
â”œâ”€ Cyclomatic Complexity: 15 (HIGH - consider refactoring)
â”œâ”€ Lines of Code: 234
â”œâ”€ Number of Parameters: 8 (too many)
â””â”€ Nested Depth: 4 levels
```

**Available Tools:**
- `coderef_scan` - Discover all code elements
- `coderef_query` - Find relationships (calls, imports, depends-on)
- `coderef_impact` - Analyze change consequences
- `coderef_complexity` - Measure code complexity
- `coderef_patterns` - Find code patterns
- `coderef_coverage` - Analyze test coverage
- `coderef_diagram` - Generate visual dependency graphs

**Your Project Stats:**
- **Total Elements Scanned:** 116,233
- **Active Servers:** 7 (coderef-context, coderef-docs, coderef-personas, coderef-testing, coderef-workflow, papertrail, mcp-workflows)
- **Languages Supported:** Python, TypeScript, JavaScript

---

### 2. ğŸ“‹ CodeRef-Workflow: The Planning & Orchestration Master

**What It Does:**
Transforms feature ideas into structured, executable implementation plans.

**The Complete Workflow:**

```
1. Feature Idea
   â†“
2. /create-workorder (gather requirements)
   â†“
3. Auto-analysis (coderef-context scans your project)
   â†“
4. 10-Section Implementation Plan Generated
   â†“
5. /execute-plan (turn plan into TodoWrite checklist)
   â†“
6. Implementation (with expert personas)
   â†“
7. /update-deliverables (track metrics)
   â†“
8. /archive-feature (complete & document)
```

**Real-World Example:**

```
User: "I want to add dark mode to my app"

/create-workorder
â”œâ”€ Gathers context (what, why, constraints)
â”œâ”€ Analyzes existing CSS/theme patterns
â”œâ”€ Creates plan.json with 10 sections:
â”‚   â”œâ”€ META_DOCUMENTATION (workorder tracking)
â”‚   â”œâ”€ 0_PREPARATION (current state)
â”‚   â”œâ”€ 1_EXECUTIVE_SUMMARY (3-5 bullets)
â”‚   â”œâ”€ 2_RISK_ASSESSMENT (breaking changes?)
â”‚   â”œâ”€ 3_CURRENT_STATE_ANALYSIS
â”‚   â”œâ”€ 4_KEY_FEATURES (must-haves)
â”‚   â”œâ”€ 5_TASK_ID_SYSTEM (naming convention)
â”‚   â”œâ”€ 6_IMPLEMENTATION_PHASES (step-by-step)
â”‚   â”œâ”€ 7_TESTING_STRATEGY (how to verify)
â”‚   â””â”€ 8_SUCCESS_CRITERIA (definition of done)
â””â”€ Validates plan (quality score 0-100)
```

**Workorder System:**

Every feature gets a unique ID:
```
Format: WO-{FEATURE}-{CATEGORY}-###
Example: WO-DARK-MODE-UI-001

Tracked in: coderef/workorder-log.txt
Stored in: coderef/workorder/{feature-name}/plan.json
```

**Available Tools:**
- `/create-workorder` - Start feature planning
- `/analyze-for-planning` - Auto-discover project patterns
- `/create-plan` - Generate implementation plan
- `/validate-plan` - Quality check (0-100 score)
- `/execute-plan` - Convert to TodoWrite checklist
- `/archive-feature` - Complete & store in archive

---

### 3. ğŸ“š CodeRef-Docs: The Documentation Automation Engine

**What It Does:**
Automatically generates and maintains documentation based on your code and git history.

**The POWER Framework:**

All docs follow this structure:
- **P**urpose - Why this exists
- **O**verview - What it covers
- **W**hat/Why/When - Detailed content
- **E**xamples - Concrete illustrations
- **R**eferences - Links to related docs

**What It Can Generate:**

```
Foundation Docs:
â”œâ”€ README.md          (project overview)
â”œâ”€ ARCHITECTURE.md    (system design, patterns, decisions)
â”œâ”€ SCHEMA.md          (database entities, relationships)
â”œâ”€ COMPONENTS.md      (UI component hierarchy - for frontend)
â”œâ”€ API.md             (endpoints, contracts)
â””â”€ CHANGELOG.json     (structured version history)

Workflow Docs:
â”œâ”€ quickref.md        (scannable quick reference)
â”œâ”€ user-guide.md      (end-user documentation)
â””â”€ my-guide.md        (developer tool guide)
```

**Automatic Changelog Updates:**

```bash
# Agent finishes feature implementation
/record-changes

# CodeRef automatically:
âœ… Detects git changes (git diff)
âœ… Suggests change type (feature/bugfix/breaking)
âœ… Calculates version bump (1.0.0 â†’ 1.1.0)
âœ… Updates CHANGELOG.json
âœ… Updates README.md "What's New" section
âœ… Adds workorder tracking metadata
```

**Standards Enforcement:**

```bash
# Establish project standards (run once)
/establish-standards

# Generates:
â”œâ”€ ui-patterns.md       (button styles, modals, forms)
â”œâ”€ behavior-patterns.md (error handling, loading states)
â”œâ”€ ux-patterns.md       (navigation, permissions)
â””â”€ standards-index.md   (overview)

# Then check compliance:
/check-consistency

# Returns violations with severity levels:
âš ï¸  MAJOR: Button uses inline styles (violates ui-patterns.md)
âš ï¸  MINOR: Loading spinner missing in async operation
```

**Available Tools:**
- `generate_foundation_docs` - Create README, ARCHITECTURE, etc.
- `record_changes` - Auto-detect & log changes
- `establish_standards` - Scan codebase for patterns
- `audit_codebase` - Find standards violations
- `check_consistency` - Pre-commit quality gate
- `validate_document` - Check UDS compliance

---

### 4. ğŸ­ CodeRef-Personas: The Expert Agent System

**What It Does:**
Gives AI agents domain expertise and specialized knowledge.

**The 9 Expert Personas:**

```
Frontend:
â”œâ”€ Ava           (React, TypeScript, UI/UX specialist)

Backend:
â”œâ”€ Marcus        (Python, APIs, databases, architecture)

Testing:
â”œâ”€ Quinn         (pytest, coverage, test strategy)

DevOps:
â”œâ”€ Morgan        (CI/CD, deployment, infrastructure)

Documentation:
â”œâ”€ Alex          (technical writing, API docs)

General Purpose:
â”œâ”€ Taylor        (full-stack, versatile problem-solver)

Coordination:
â”œâ”€ Lloyd         (multi-agent orchestration, workorder tracking)

Research:
â””â”€ Scout         (codebase exploration, pattern discovery)
```

**How It Works:**

```bash
# Activate an expert
/ava  # Frontend specialist

# Agent behavior changes:
Before: Generic coding responses
After:
  â”œâ”€ Uses React best practices
  â”œâ”€ Follows TypeScript patterns
  â”œâ”€ Applies accessibility standards
  â”œâ”€ Suggests modern UI patterns
  â””â”€ References component libraries
```

**Real Example:**

```
# Without Persona
Agent: "I'll add a button using standard HTML"
<button onclick="handleClick()">Click Me</button>

# With Ava (Frontend Specialist)
Agent: "I'll use your existing Button component with proper typing"
<Button
  variant="primary"
  onClick={handleClick}
  aria-label="Submit form"
>
  Click Me
</Button>
```

**Create Custom Personas:**

```bash
/create-persona
  Name: security-expert
  Expertise: ["penetration testing", "OWASP top 10", "secure coding"]
  Communication: "Direct, security-focused, flags vulnerabilities"
```

**Available Tools:**
- `use_persona` - Activate expert (9 built-in)
- `create_custom_persona` - Build your own specialist
- `list_personas` - See all available experts
- `get_active_persona` - Check current expert
- `clear_persona` - Return to default behavior

---

### 5. ğŸ§ª CodeRef-Testing: The Test Automation Engine

**What It Does:**
Runs tests, tracks coverage, generates reports, and identifies gaps.

**Capabilities:**

```bash
# Run all tests
/run-tests

# Returns:
Test Results:
â”œâ”€ 847 tests passed
â”œâ”€ 3 tests failed
â”œâ”€ 12 tests skipped
â”œâ”€ Duration: 45.2 seconds
â””â”€ Coverage: 87%

# Get detailed coverage
/test-coverage

Coverage Report:
â”œâ”€ server.py: 95% (well tested)
â”œâ”€ generators/: 82% (good coverage)
â”œâ”€ utils/helpers.py: 45% (needs tests âš ï¸)
â””â”€ handlers/auth.py: 0% (untested âŒ)
```

**Test Health Monitoring:**

```bash
/test-health

Health Score: 73/100

Issues Found:
â”œâ”€ 5 slow tests (>10 seconds each)
â”œâ”€ 12 flaky tests (intermittent failures)
â”œâ”€ 23 functions without tests
â””â”€ 8 deprecated test fixtures

Recommendations:
â”œâ”€ Add tests for handlers/auth.py
â”œâ”€ Refactor slow database tests
â””â”€ Update pytest fixtures in conftest.py
```

**Available Tools:**
- `run_tests` - Execute pytest suite
- `test_coverage` - Coverage analysis
- `test_health` - Quality scoring
- `discover_tests` - Find all test files
- `run_specific_tests` - Target specific modules

---

## The Complete Feature Lifecycle

**From Idea to Production in 4 Phases:**

### Phase 1: PLAN (5-10 minutes)

```bash
/create-workorder
  Feature: "Add JWT authentication"

# What Happens:
â”œâ”€ Interactive Q&A (gathers requirements)
â”œâ”€ Project analysis (scans existing auth patterns)
â”œâ”€ Plan generation (10-section plan.json)
â”œâ”€ Validation (quality score check)
â””â”€ Output: WO-AUTH-SYSTEM-001 ready for execution
```

**Plan Structure:**
```json
{
  "META_DOCUMENTATION": {
    "workorder_id": "WO-AUTH-SYSTEM-001",
    "version": "1.0.0",
    "status": "approved"
  },
  "6_IMPLEMENTATION_PHASES": {
    "phase_1": {
      "name": "Setup JWT Infrastructure",
      "tasks": [
        {
          "id": "SETUP-001",
          "description": "Install PyJWT dependency",
          "estimated_effort": "15 minutes"
        }
      ]
    }
  }
}
```

---

### Phase 2: EXECUTE (1-8 hours)

```bash
/execute-plan --feature auth-system

# Converts plan.json to TodoWrite checklist:
â˜ WO-AUTH-SYSTEM-001 | SETUP-001: Install PyJWT dependency
â˜ WO-AUTH-SYSTEM-001 | IMPL-001: Create JWT token generator
â˜ WO-AUTH-SYSTEM-001 | IMPL-002: Add token validation middleware
â˜ WO-AUTH-SYSTEM-001 | TEST-001: Write unit tests for auth

# Activate expert persona
/marcus  # Backend specialist

# Agent implements tasks with:
â”œâ”€ Full code context (from coderef-context)
â”œâ”€ Best practices (from persona)
â”œâ”€ Pattern awareness (from project analysis)
â””â”€ Progress tracking (TodoWrite)
```

**Multi-Agent Mode:**

For complex features, split work across agents:

```bash
/generate-agent-communication --feature auth-system

# Creates communication.json:
{
  "agent_1": {
    "name": "Marcus",
    "tasks": ["IMPL-001", "IMPL-002"],
    "forbidden_files": ["frontend/*", "tests/*"]
  },
  "agent_2": {
    "name": "Quinn",
    "tasks": ["TEST-001", "TEST-002"],
    "forbidden_files": ["src/*"]
  }
}

# Agents work in parallel, verify completion:
/verify-agent-completion --agent 1
/verify-agent-completion --agent 2
```

---

### Phase 3: DOCUMENT (2-5 minutes)

```bash
# Capture implementation metrics
/update-deliverables --feature auth-system

# Auto-detects from git:
Metrics Captured:
â”œâ”€ Lines of Code: +487 (added), -23 (removed)
â”œâ”€ Files Changed: 12
â”œâ”€ Commits: 8
â”œâ”€ Contributors: ["Marcus (agent)", "willh"]
â”œâ”€ Time Elapsed: 3.5 hours
â””â”€ Tests Added: 15

# Record changes in changelog
/record-changes --version 1.1.0

# Updates:
â”œâ”€ CHANGELOG.json (structured entry)
â”œâ”€ README.md (What's New section)
â””â”€ CLAUDE.md (version history)
```

---

### Phase 4: ARCHIVE (1 minute)

```bash
/archive-feature --feature auth-system

# Moves to archive:
coderef/workorder/auth-system/
  â†“
coderef/archived/auth-system/
  â”œâ”€ plan.json
  â”œâ”€ DELIVERABLES.md
  â”œâ”€ context.json
  â””â”€ analysis.json

# Updates archive index:
Archive Index:
â”œâ”€ auth-system (completed 2025-12-30)
â”œâ”€ dark-mode (completed 2025-12-28)
â””â”€ api-v2 (completed 2025-12-15)
```

**Why Archive?**
- Historical reference for similar features
- Recovery if needed
- Pattern discovery for future planning
- Knowledge base for AI agents

---

## Practical Queries: What You Can Ask

### Code Intelligence Queries

**"What calls this function?"**
```bash
coderef query --type calls-me --target authenticateUser

# Returns:
Functions calling authenticateUser():
â”œâ”€ src/api/routes.py:45 â†’ loginHandler()
â”œâ”€ src/api/middleware.py:89 â†’ authMiddleware()
â””â”€ tests/test_auth.py:12 â†’ test_valid_token()
```

**"What does this import?"**
```bash
coderef query --type imports --target server.py

# Returns:
server.py imports:
â”œâ”€ generators.planning_generator
â”œâ”€ handlers.auth_handler
â””â”€ utils.validation
```

**"Is this safe to delete?"**
```bash
coderef impact --element oldLegacyFunction --operation delete

# Returns:
âš ï¸  DANGER: 23 files still use this function
Files affected:
â”œâ”€ src/legacy/auth.py:156
â”œâ”€ src/api/routes.py:234
â””â”€ ... (21 more)

Recommendation: Migrate dependencies before deleting
```

---

### Planning & Documentation Queries

**"Show me the plan for this feature"**
```bash
# Read plan
cat coderef/workorder/auth-system/plan.json

# Or use MCP tool
get_planning_template --section 6_implementation_phases
```

**"What features are in progress?"**
```bash
# Generate features inventory
generate_features_inventory --format markdown

# Returns:
Active Features:
â”œâ”€ auth-system (75% complete, 12/16 tasks done)
â”œâ”€ dark-mode (planning phase)
â””â”€ api-v2 (testing phase)

Archived Features:
â”œâ”€ user-profiles (completed 2025-12-20)
â””â”€ dashboard-redesign (completed 2025-12-15)
```

**"What changed in version 1.2.0?"**
```bash
get_changelog --version 1.2.0

# Returns:
Version 1.2.0 (2025-12-30):
â”œâ”€ Type: feature
â”œâ”€ Description: Added JWT authentication with refresh tokens
â”œâ”€ Files: 12 changed
â”œâ”€ Workorder: WO-AUTH-SYSTEM-001
â””â”€ Impact: All API endpoints now require authentication
```

---

### Testing Queries

**"What needs tests?"**
```bash
test_coverage --format detailed

# Returns:
Coverage Gaps:
â”œâ”€ handlers/auth.py: 0% (23 functions untested âŒ)
â”œâ”€ utils/helpers.py: 45% (12 functions need tests âš ï¸)
â””â”€ generators/plan.py: 95% (well tested âœ…)
```

**"Are tests healthy?"**
```bash
test_health

# Returns:
Health Score: 68/100

Issues:
â”œâ”€ 15 slow tests (>5 seconds)
â”œâ”€ 3 flaky tests (fail intermittently)
â””â”€ 45 functions without coverage

Recommendations:
â”œâ”€ Add fixtures for database tests
â”œâ”€ Mock external API calls
â””â”€ Increase timeout for integration tests
```

---

## The Power of Integration

**How the Servers Work Together:**

```
Feature Request: "Add user authentication"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. coderef-workflow: Create plan                    â”‚
â”‚    â”œâ”€ Calls coderef-context (scan existing code)   â”‚
â”‚    â”œâ”€ Activates coderef-personas (Marcus/backend)  â”‚
â”‚    â””â”€ Creates WO-AUTH-001                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. coderef-context: Analyze impact                  â”‚
â”‚    â”œâ”€ Find existing auth patterns                   â”‚
â”‚    â”œâ”€ Check dependencies                            â”‚
â”‚    â””â”€ Return complexity metrics                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. coderef-personas: Execute with expertise         â”‚
â”‚    â”œâ”€ Marcus implements backend logic               â”‚
â”‚    â”œâ”€ Quinn writes tests                            â”‚
â”‚    â””â”€ Uses patterns from coderef-context            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. coderef-testing: Validate implementation         â”‚
â”‚    â”œâ”€ Run test suite                                â”‚
â”‚    â”œâ”€ Check coverage                                â”‚
â”‚    â””â”€ Report health score                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. coderef-docs: Document everything                â”‚
â”‚    â”œâ”€ Update CHANGELOG.json                         â”‚
â”‚    â”œâ”€ Generate API docs                             â”‚
â”‚    â””â”€ Archive completed feature                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Complete, tested, documented feature âœ…
```

---

## Your Project: By the Numbers

**Current State (as of 2025-12-30):**

```
Total Code Elements Scanned: 116,233
  â”œâ”€ Functions: ~45,000
  â”œâ”€ Classes: ~18,000
  â”œâ”€ Methods: ~53,000
  â””â”€ Exports: ~12,000

Active MCP Servers: 7
  â”œâ”€ coderef-context (595K)
  â”œâ”€ coderef-docs (102M - largest)
  â”œâ”€ coderef-personas (11M)
  â”œâ”€ coderef-testing (1.6M)
  â”œâ”€ coderef-workflow (7.4M)
  â”œâ”€ papertrail (501K)
  â””â”€ mcp-workflows (108K)

Languages Supported:
  â”œâ”€ Python (.py)
  â”œâ”€ TypeScript (.ts)
  â””â”€ JavaScript (.js)

Foundation Docs:
  â”œâ”€ CLAUDE.md (ecosystem overview)
  â”œâ”€ README.md (user guide)
  â””â”€ Individual server docs (5 files)
```

---

## What We're Discovering Together

**This guide is a living document.** As we explore the CodeRef ecosystem, we'll uncover:

### Features Yet to Discover
- â³ Advanced dependency visualization
- â³ Cross-repository analysis
- â³ Semantic code search
- â³ Pattern library generation
- â³ Automated refactoring suggestions
- â³ Code quality dashboards

### Workflows to Explore
- Multi-agent feature implementation
- Automated migration planning
- Legacy code modernization
- API versioning strategies
- Test suite optimization

### Integration Possibilities
- CI/CD pipeline integration
- IDE plugins
- Code review automation
- Documentation generation pipelines
- Real-time collaboration features

---

## Quick Reference: Essential Commands

**Planning & Execution:**
```bash
/create-workorder        # Start feature planning
/analyze-for-planning    # Auto-discover project patterns
/create-plan            # Generate implementation plan
/execute-plan           # Convert plan to tasks
/archive-feature        # Complete and store feature
```

**Code Intelligence:**
```bash
coderef scan            # Discover all code elements
coderef query           # Find relationships
coderef impact          # Analyze change consequences
coderef complexity      # Measure code quality
coderef diagram         # Generate visualizations
```

**Documentation:**
```bash
/generate-docs          # Create foundation docs
/record-changes         # Update changelog
/establish-standards    # Scan for patterns
/check-consistency      # Validate compliance
```

**Testing:**
```bash
/run-tests              # Execute test suite
/test-coverage          # Coverage analysis
/test-health            # Quality scoring
```

**Personas:**
```bash
/ava                    # Frontend specialist
/marcus                 # Backend specialist
/quinn                  # Testing specialist
/lloyd                  # Multi-agent coordinator
/taylor                 # General purpose
```

---

## Getting Started

**First-Time Setup:**

1. **Scan your project:**
   ```bash
   coderef scan --project-path /your/project
   ```

2. **Generate foundation docs:**
   ```bash
   /generate-docs
   ```

3. **Establish coding standards:**
   ```bash
   /establish-standards
   ```

4. **Create your first workorder:**
   ```bash
   /create-workorder
   ```

**Next Steps:**
- Explore the coderef query tools
- Activate different personas
- Run test coverage analysis
- Generate your first implementation plan

---

## Learn More

**Documentation:**
- `CLAUDE.md` - Technical architecture for AI agents
- `README.md` - Installation and quick start
- `coderef-context/CLAUDE.md` - Code intelligence details
- `coderef-workflow/CLAUDE.md` - Planning workflows
- `coderef-docs/CLAUDE.md` - Documentation system
- `coderef-personas/CLAUDE.md` - Persona system
- `coderef-testing/CLAUDE.md` - Test automation

**Support:**
- GitHub Issues: Report bugs and request features
- Discussions: Ask questions and share workflows

---

## Appendix: File Locations

**Global Artifacts:**
```
~/.mcp-servers/
â”œâ”€ CLAUDE.md                    # Ecosystem overview (this file)
â”œâ”€ CODEREF-ECOSYSTEM-GUIDE.md   # Human user guide (you are here)
â”œâ”€ README.md                    # Quick start
â”œâ”€ coderef/
â”‚   â”œâ”€ workorder/               # Active features
â”‚   â”œâ”€ archived/                # Completed features
â”‚   â”œâ”€ workorder-log.txt        # Audit trail
â”‚   â””â”€ standards/               # Coding standards
â””â”€ [server-name]/
    â”œâ”€ server.py                # MCP server
    â”œâ”€ CLAUDE.md                # Server docs
    â””â”€ .claude/commands/        # Slash commands
```

**Configuration:**
```
~/.mcp.json                     # MCP server configuration
~/.claude/settings.json         # Claude Code settings
```

---

## Document History

**Version 1.0.0 (2025-12-30):**
- âœ… Initial guide creation
- âœ… Documented coderef scan capabilities
- âœ… Described all 5 MCP servers
- âœ… Added complete feature lifecycle
- âœ… Included practical query examples
- âœ… Captured project statistics (116K elements)
- âœ… Established living document framework

**Future Additions:**
- [ ] Advanced query patterns
- [ ] Multi-agent coordination examples
- [ ] Performance optimization tips
- [ ] Troubleshooting guide
- [ ] Video tutorials/demos
- [ ] Community contributions

---

**Generated with:** CodeRef Ecosystem v1.0.0
**AI Assistant:** Claude (Anthropic)
**Maintained by:** willh + community
**License:** See LICENSE file

---

*This is a living document. As we discover new features and capabilities, this guide will evolve. Join us on the journey of building the ultimate AI-assisted development workflow.*
