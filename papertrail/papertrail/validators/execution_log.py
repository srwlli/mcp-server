"""
ExecutionLogValidator - Validates execution log JSON files

Validates execution logs generated by coderef-workflow against:
1. execution-log-json-schema.json - Schema structure
2. Cross-validation - Verifies task_id references exist in plan.json (optional)

Scores execution logs 0-100 based on schema compliance and cross-validation.
"""

from pathlib import Path
from typing import Optional, Union, List, Dict, Any
import json
import re
from jsonschema import Draft7Validator, ValidationError as JsonSchemaValidationError

from ..validator import ValidationResult, ValidationError, ValidationSeverity


class ExecutionLogValidator:
    """
    Validator for execution log JSON files

    Validates execution logs against JSON Schema Draft-07 schema and performs
    cross-validation with corresponding plan.json to ensure task_id references are valid.
    """

    def __init__(self, schemas_dir: Optional[Path] = None):
        """
        Initialize validator with schemas directory

        Args:
            schemas_dir: Path to schemas directory (default: package schemas/workflow/)
        """
        if schemas_dir is None:
            # Default to schemas/workflow/ for workflow schemas
            schemas_dir = Path(__file__).parent.parent.parent / "schemas" / "workflow"

        self.schemas_dir = schemas_dir
        self.schema = None
        self._load_schema()

    def _load_schema(self):
        """Load execution-log-json-schema.json"""
        schema_path = self.schemas_dir / "execution-log-json-schema.json"
        if not schema_path.exists():
            raise FileNotFoundError(f"Schema not found: {schema_path}")

        with open(schema_path, 'r', encoding='utf-8') as f:
            self.schema = json.load(f)

    def validate_file(self, file_path: Union[str, Path], enable_cross_validation: bool = True) -> ValidationResult:
        """
        Validate an execution log JSON file

        Args:
            file_path: Path to execution-log.json file
            enable_cross_validation: Whether to perform cross-validation with plan.json (default: True)

        Returns:
            ValidationResult with errors, warnings, and score
        """
        file_path = Path(file_path)

        if not file_path.exists():
            return ValidationResult(
                valid=False,
                errors=[ValidationError(
                    severity=ValidationSeverity.CRITICAL,
                    message=f"File not found: {file_path}"
                )],
                warnings=[],
                score=0
            )

        # Read JSON content
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            return ValidationResult(
                valid=False,
                errors=[ValidationError(
                    severity=ValidationSeverity.CRITICAL,
                    message=f"Invalid JSON: {str(e)}"
                )],
                warnings=[],
                score=0
            )

        return self.validate_content(data, file_path, enable_cross_validation)

    def validate_content(
        self,
        data: Union[List[Dict[str, Any]], Dict[str, Any]],
        file_path: Optional[Path] = None,
        enable_cross_validation: bool = True
    ) -> ValidationResult:
        """
        Validate execution log data

        Args:
            data: Execution log data (array of execution log entries)
            file_path: Optional path for context and cross-validation
            enable_cross_validation: Whether to perform cross-validation with plan.json

        Returns:
            ValidationResult with errors, warnings, and score
        """
        errors = []
        warnings = []

        # JSON Schema validation
        validator = Draft7Validator(self.schema)
        schema_errors = list(validator.iter_errors(data))

        for error in schema_errors:
            # Convert jsonschema errors to ValidationError
            path = " -> ".join(str(p) for p in error.path) if error.path else "root"
            errors.append(ValidationError(
                severity=ValidationSeverity.MAJOR,
                message=f"Schema validation failed at {path}: {error.message}",
                field=path
            ))

        # Additional validation checks
        if isinstance(data, list):
            for idx, entry in enumerate(data):
                if not isinstance(entry, dict):
                    continue

                # Validate workorder_id format
                if 'workorder_id' in entry:
                    workorder_id = entry['workorder_id']
                    if not re.match(r'^WO-[A-Z0-9]+-[A-Z0-9]+-\d{3}$', workorder_id):
                        errors.append(ValidationError(
                            severity=ValidationSeverity.MAJOR,
                            message=f"Invalid workorder_id format: {workorder_id}. Expected: WO-{{CATEGORY}}-{{ID}}-###",
                            field=f"[{idx}].workorder_id"
                        ))

                # Validate feature_name format (kebab-case)
                if 'feature_name' in entry:
                    feature_name = entry['feature_name']
                    if not re.match(r'^[a-z0-9]+(-[a-z0-9]+)*$', feature_name):
                        errors.append(ValidationError(
                            severity=ValidationSeverity.MAJOR,
                            message=f"Invalid feature_name format: {feature_name}. Expected: kebab-case",
                            field=f"[{idx}].feature_name"
                        ))

                # Validate task_count matches tasks array length
                if 'task_count' in entry and 'tasks' in entry:
                    declared_count = entry['task_count']
                    actual_count = len(entry['tasks'])
                    if declared_count != actual_count:
                        errors.append(ValidationError(
                            severity=ValidationSeverity.MINOR,
                            message=f"task_count mismatch: declared {declared_count}, actual {actual_count}",
                            field=f"[{idx}].task_count"
                        ))

                # Cross-validation with plan.json (optional)
                if enable_cross_validation and file_path:
                    self._cross_validate_with_plan(entry, file_path, idx, errors, warnings)

        # Calculate score
        score = self._calculate_score(errors, warnings)

        return ValidationResult(
            valid=score >= 90,
            errors=errors,
            warnings=warnings,
            score=score
        )

    def _cross_validate_with_plan(
        self,
        entry: Dict[str, Any],
        execution_log_path: Path,
        entry_idx: int,
        errors: List[ValidationError],
        warnings: List[str]
    ):
        """
        Cross-validate task_id references with plan.json

        Attempts to find plan.json in:
        1. Same directory as execution-log.json
        2. Parent directory (for nested structures)

        Args:
            entry: Execution log entry to validate
            execution_log_path: Path to execution log file
            entry_idx: Index of entry in array
            errors: List to append errors to
            warnings: List to append warnings to
        """
        # Try to find plan.json
        plan_paths = [
            execution_log_path.parent / "plan.json",  # Same directory
            execution_log_path.parent.parent / "plan.json"  # Parent directory
        ]

        plan_path = None
        for path in plan_paths:
            if path.exists():
                plan_path = path
                break

        if not plan_path:
            warnings.append(f"Cross-validation skipped: plan.json not found near {execution_log_path}")
            return

        # Load plan.json
        try:
            with open(plan_path, 'r', encoding='utf-8') as f:
                plan_data = json.load(f)
        except (json.JSONDecodeError, IOError) as e:
            warnings.append(f"Cross-validation failed: Could not load plan.json: {str(e)}")
            return

        # Extract valid task IDs from plan.json
        valid_task_ids = self._extract_task_ids_from_plan(plan_data)

        if not valid_task_ids:
            warnings.append("Cross-validation skipped: No task IDs found in plan.json")
            return

        # Validate each task in execution log
        tasks = entry.get('tasks', [])
        for task_idx, task in enumerate(tasks):
            if not isinstance(task, dict):
                continue

            # Extract task ID from content field (format: "TASK-ID: description")
            content = task.get('content', '')
            task_id_match = re.match(r'^([A-Z0-9-]+):', content)

            if task_id_match:
                task_id = task_id_match.group(1)

                # Check if task_id exists in plan.json
                if task_id not in valid_task_ids:
                    errors.append(ValidationError(
                        severity=ValidationSeverity.MAJOR,
                        message=f"Task ID '{task_id}' not found in plan.json. Cross-validation failed.",
                        field=f"[{entry_idx}].tasks[{task_idx}].content"
                    ))

    def _extract_task_ids_from_plan(self, plan_data: Dict[str, Any]) -> set:
        """
        Extract all task IDs from plan.json

        Supports plan.schema.json structure:
        - UNIVERSAL_PLANNING_STRUCTURE.5_task_id_system.tasks[].id

        Args:
            plan_data: Parsed plan.json data

        Returns:
            Set of valid task IDs
        """
        task_ids = set()

        # Extract from UNIVERSAL_PLANNING_STRUCTURE.5_task_id_system.tasks
        if 'UNIVERSAL_PLANNING_STRUCTURE' in plan_data:
            structure = plan_data['UNIVERSAL_PLANNING_STRUCTURE']

            if '5_task_id_system' in structure:
                task_system = structure['5_task_id_system']

                if 'tasks' in task_system and isinstance(task_system['tasks'], list):
                    for task in task_system['tasks']:
                        if isinstance(task, dict) and 'id' in task:
                            task_ids.add(task['id'])

        return task_ids

    def _calculate_score(self, errors: List[ValidationError], warnings: List[str]) -> int:
        """
        Calculate validation score (0-100)

        Formula: 100 - 50*CRITICAL - 20*MAJOR - 10*MINOR - 5*WARNING - 2*warnings

        Args:
            errors: List of validation errors
            warnings: List of warning messages

        Returns:
            Score (0-100)
        """
        score = 100

        for error in errors:
            if error.severity == ValidationSeverity.CRITICAL:
                score -= 50
            elif error.severity == ValidationSeverity.MAJOR:
                score -= 20
            elif error.severity == ValidationSeverity.MINOR:
                score -= 10
            elif error.severity == ValidationSeverity.WARNING:
                score -= 5

        score -= 2 * len(warnings)

        return max(0, score)
