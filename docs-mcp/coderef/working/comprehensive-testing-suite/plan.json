{
  "META_DOCUMENTATION": {
    "feature_name": "comprehensive-testing-suite",
    "schema_version": "1.0.0",
    "version": "1.0.0",
    "status": "complete",
    "generated_by": "Lloyd (Project Orchestrator)",
    "generated_at": "2025-12-07T22:56:00Z",
    "has_context": true,
    "has_analysis": true
  },
  "UNIVERSAL_PLANNING_STRUCTURE": {
    "0_preparation": {
      "foundation_docs": {
        "available": ["README.md", "USER-GUIDE.md", "CLAUDE.md"],
        "missing": ["API.md", "ARCHITECTURE.md"],
        "relevant_content": "docs-mcp v2.9.0 - Enterprise MCP server with 138 files, 25 generators"
      },
      "coding_standards": {
        "location": "Not established",
        "key_patterns": ["Python 3.10+", "pytest", "async/await patterns", "MCP protocol"]
      },
      "reference_components": {
        "primary": "generators/context_expert_generator.py",
        "secondary": ["server.py", "tool_handlers.py"]
      },
      "project_analysis": {
        "total_files": 138,
        "test_files_existing": 15,
        "generators_to_test": 25,
        "coverage_gap": "Significant - most generators lack unit tests"
      }
    },
    "1_executive_summary": {
      "feature_name": "Comprehensive Testing Suite",
      "description": "Establish complete test coverage across the MCP ecosystem (docs-mcp, coderef-mcp, personas-mcp) with unit tests, integration tests, and performance tests.",
      "goal": "Ensure reliability, catch regressions, and enable confident refactoring with organized test packages per server.",
      "scope": "All three MCP servers with focus on generators, tool handlers, and MCP workflows",
      "estimated_complexity": "High",
      "key_stakeholders": ["willh", "Claude Code AI"]
    },
    "2_risk_assessment": {
      "risks": [
        {
          "id": "RISK-001",
          "description": "Large scope across 3 servers may cause scope creep",
          "severity": "medium",
          "mitigation": "Phase by server, start with docs-mcp which has most infrastructure"
        },
        {
          "id": "RISK-002",
          "description": "Async/await patterns in MCP server require careful test setup",
          "severity": "medium",
          "mitigation": "Use pytest-asyncio, create reusable test fixtures"
        },
        {
          "id": "RISK-003",
          "description": "Integration tests may be slow with file I/O",
          "severity": "low",
          "mitigation": "Use tmp_path fixtures, mark slow tests for CI optimization"
        }
      ],
      "dependencies": [
        "pytest",
        "pytest-asyncio",
        "pytest-cov"
      ],
      "blockers": []
    },
    "3_current_state_analysis": {
      "files_to_create": [
        {"path": "tests/conftest.py", "purpose": "Shared fixtures for all tests"},
        {"path": "tests/unit/generators/test_context_expert_generator.py", "purpose": "Unit tests for context expert system"},
        {"path": "tests/unit/generators/test_foundation_generator.py", "purpose": "Unit tests for foundation doc generator"},
        {"path": "tests/unit/generators/test_planning_generator.py", "purpose": "Unit tests for planning workflow"},
        {"path": "tests/unit/generators/test_changelog_generator.py", "purpose": "Unit tests for changelog management"},
        {"path": "tests/unit/generators/test_inventory_generators.py", "purpose": "Unit tests for inventory tools"},
        {"path": "tests/unit/test_server.py", "purpose": "Unit tests for MCP server core"},
        {"path": "tests/unit/test_tool_handlers.py", "purpose": "Unit tests for tool dispatch"},
        {"path": "tests/integration/test_mcp_workflows.py", "purpose": "Full MCP tool workflow tests"},
        {"path": "tests/integration/test_planning_workflow.py", "purpose": "End-to-end planning tests"},
        {"path": "tests/performance/test_large_projects.py", "purpose": "Performance tests for scanning"},
        {"path": "tests/performance/test_query_performance.py", "purpose": "Performance tests for queries"}
      ],
      "files_to_modify": [
        {"path": "pyproject.toml", "purpose": "Add test dependencies and pytest config"},
        {"path": "tests/unit/handlers/__init__.py", "purpose": "Ensure proper package structure"}
      ],
      "files_to_delete": [],
      "current_test_structure": {
        "tests/unit/handlers": "8 existing handler tests",
        "tests/integration": "7 existing integration tests including context_expert_workflow"
      }
    },
    "4_key_features": {
      "features": [
        {
          "id": "FEAT-001",
          "name": "Generator Unit Tests",
          "description": "Comprehensive unit tests for all 25 generators in docs-mcp",
          "priority": "P0",
          "requirements": ["Test each public method", "Mock file I/O", "Test error handling"]
        },
        {
          "id": "FEAT-002",
          "name": "Context Expert Tests",
          "description": "Tests for the context expert system (create, list, get, suggest, update, activate)",
          "priority": "P0",
          "requirements": ["Test ID generation", "Test expert lifecycle", "Test staleness calculation"]
        },
        {
          "id": "FEAT-003",
          "name": "MCP Integration Tests",
          "description": "Full workflow tests that exercise MCP tool calls end-to-end",
          "priority": "P1",
          "requirements": ["Test tool registration", "Test tool dispatch", "Test error responses"]
        },
        {
          "id": "FEAT-004",
          "name": "Performance Tests",
          "description": "Benchmarks for large project scanning and query performance",
          "priority": "P2",
          "requirements": ["Create large mock projects", "Set performance baselines", "Detect regressions"]
        }
      ]
    },
    "5_task_id_system": {
      "workorder": {
        "id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
        "name": "Comprehensive Testing Suite",
        "feature_dir": "coderef/working/comprehensive-testing-suite"
      },
      "tasks": [
        {
          "id": "SETUP-001",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create tests/conftest.py with shared fixtures (tmp_path, mock_project, async event loop)",
          "priority": "P0",
          "estimated_loc": 150,
          "dependencies": [],
          "acceptance_criteria": ["Fixtures importable from all test files", "tmp_path creates valid project structure"]
        },
        {
          "id": "SETUP-002",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Update pyproject.toml with pytest, pytest-asyncio, pytest-cov dependencies",
          "priority": "P0",
          "estimated_loc": 30,
          "dependencies": [],
          "acceptance_criteria": ["pytest runs successfully", "Coverage reporting works"]
        },
        {
          "id": "UNIT-001",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create unit tests for ContextExpertGenerator (create, list, get, suggest)",
          "priority": "P0",
          "estimated_loc": 300,
          "dependencies": ["SETUP-001"],
          "acceptance_criteria": ["All 6 expert methods tested", "ID generation edge cases covered", "90%+ coverage"]
        },
        {
          "id": "UNIT-002",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create unit tests for FoundationGenerator (README, API, ARCHITECTURE templates)",
          "priority": "P0",
          "estimated_loc": 250,
          "dependencies": ["SETUP-001"],
          "acceptance_criteria": ["Template loading tested", "Output format validated", "Error handling verified"]
        },
        {
          "id": "UNIT-003",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create unit tests for PlanningGenerator (context, analysis, plan creation)",
          "priority": "P0",
          "estimated_loc": 300,
          "dependencies": ["SETUP-001"],
          "acceptance_criteria": ["Plan schema validation tested", "Workorder ID generation tested", "Phase structure validated"]
        },
        {
          "id": "UNIT-004",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create unit tests for ChangelogGenerator (add entry, get changelog, versioning)",
          "priority": "P1",
          "estimated_loc": 200,
          "dependencies": ["SETUP-001"],
          "acceptance_criteria": ["Entry format validated", "Version bumping tested", "Breaking change detection tested"]
        },
        {
          "id": "UNIT-005",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create unit tests for InventoryGenerators (manifest, api, config, tests, docs)",
          "priority": "P1",
          "estimated_loc": 400,
          "dependencies": ["SETUP-001"],
          "acceptance_criteria": ["Each inventory type tested", "File scanning validated", "Security masking verified"]
        },
        {
          "id": "UNIT-006",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create unit tests for server.py (list_tools, call_tool dispatch)",
          "priority": "P0",
          "estimated_loc": 200,
          "dependencies": ["SETUP-001"],
          "acceptance_criteria": ["Tool registration tested", "Dispatch routing tested", "Error responses validated"]
        },
        {
          "id": "INTEG-001",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create integration tests for full MCP tool workflows (foundation docs generation)",
          "priority": "P1",
          "estimated_loc": 250,
          "dependencies": ["UNIT-001", "UNIT-002"],
          "acceptance_criteria": ["End-to-end workflow passes", "Output files validated", "Cleanup verified"]
        },
        {
          "id": "INTEG-002",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create integration tests for planning workflow (context -> analysis -> plan -> validate)",
          "priority": "P1",
          "estimated_loc": 300,
          "dependencies": ["UNIT-003"],
          "acceptance_criteria": ["Full planning pipeline tested", "Validation scoring tested", "Multi-agent flow tested"]
        },
        {
          "id": "PERF-001",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create performance tests for large project scanning (100+ files)",
          "priority": "P2",
          "estimated_loc": 150,
          "dependencies": ["SETUP-001"],
          "acceptance_criteria": ["Baseline established", "No regressions > 20%", "Memory usage tracked"]
        },
        {
          "id": "PERF-002",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Create performance tests for context expert queries",
          "priority": "P2",
          "estimated_loc": 100,
          "dependencies": ["UNIT-001"],
          "acceptance_criteria": ["Query time < 100ms for 50 experts", "Suggest time < 500ms"]
        },
        {
          "id": "DOC-001",
          "workorder_id": "WO-COMPREHENSIVE-TESTING-SUITE-001",
          "description": "Update CLAUDE.md with testing section and coverage requirements",
          "priority": "P1",
          "estimated_loc": 50,
          "dependencies": ["UNIT-006"],
          "acceptance_criteria": ["Testing commands documented", "Coverage thresholds defined", "CI guidance included"]
        }
      ]
    },
    "6_implementation_phases": {
      "phases": [
        {
          "phase": 1,
          "name": "Test Infrastructure Setup",
          "description": "Establish shared test infrastructure with fixtures and dependencies",
          "tasks": ["SETUP-001", "SETUP-002"],
          "deliverables": ["tests/conftest.py", "Updated pyproject.toml"],
          "success_criteria": "pytest runs with fixtures available to all tests"
        },
        {
          "phase": 2,
          "name": "Core Unit Tests",
          "description": "Unit tests for critical generators and server core",
          "tasks": ["UNIT-001", "UNIT-002", "UNIT-003", "UNIT-006"],
          "deliverables": ["Generator unit tests", "Server unit tests", "80%+ coverage on core"],
          "success_criteria": "All P0 unit tests pass with 80%+ coverage"
        },
        {
          "phase": 3,
          "name": "Extended Unit Tests & Integration",
          "description": "Additional unit tests and integration test suite",
          "tasks": ["UNIT-004", "UNIT-005", "INTEG-001", "INTEG-002"],
          "deliverables": ["Complete unit test suite", "Integration test workflows"],
          "success_criteria": "Full workflow tests pass end-to-end"
        },
        {
          "phase": 4,
          "name": "Performance Tests & Documentation",
          "description": "Performance benchmarks and documentation updates",
          "tasks": ["PERF-001", "PERF-002", "DOC-001"],
          "deliverables": ["Performance baselines", "Updated CLAUDE.md"],
          "success_criteria": "Performance baselines established, docs updated"
        }
      ]
    },
    "7_testing_strategy": {
      "unit_tests": {
        "framework": "pytest",
        "coverage_target": "80%",
        "key_areas": ["Generators", "Server core", "Tool handlers", "Validation"]
      },
      "integration_tests": {
        "framework": "pytest with fixtures",
        "scope": "Full MCP tool workflows",
        "key_workflows": ["Foundation docs generation", "Planning pipeline", "Context expert lifecycle"]
      },
      "performance_tests": {
        "framework": "pytest-benchmark",
        "baselines": ["Large project scan < 5s", "Expert query < 100ms"],
        "regression_threshold": "20%"
      },
      "test_data": {
        "mock_projects": "Created via tmp_path fixtures",
        "sample_files": "Inline Python/TypeScript snippets",
        "cleanup": "Automatic via pytest fixtures"
      }
    },
    "8_success_criteria": {
      "functional": [
        "All unit tests pass (0 failures)",
        "All integration tests pass",
        "Performance baselines met"
      ],
      "quality": [
        "80%+ code coverage on generators",
        "90%+ coverage on context expert system",
        "No flaky tests"
      ],
      "documentation": [
        "CLAUDE.md updated with testing section",
        "Test README with run instructions"
      ],
      "acceptance": [
        "pytest runs clean from project root",
        "CI-ready configuration",
        "Coverage report generates correctly"
      ]
    },
    "9_implementation_checklist": {
      "phase_1_checklist": [
        "[ ] Create tests/conftest.py with shared fixtures",
        "[ ] Update pyproject.toml with test dependencies",
        "[ ] Verify pytest discovers all test files"
      ],
      "phase_2_checklist": [
        "[ ] Implement ContextExpertGenerator unit tests",
        "[ ] Implement FoundationGenerator unit tests",
        "[ ] Implement PlanningGenerator unit tests",
        "[ ] Implement server.py unit tests",
        "[ ] Achieve 80%+ coverage on core modules"
      ],
      "phase_3_checklist": [
        "[ ] Implement ChangelogGenerator unit tests",
        "[ ] Implement InventoryGenerator unit tests",
        "[ ] Implement MCP workflow integration tests",
        "[ ] Implement planning workflow integration tests"
      ],
      "phase_4_checklist": [
        "[ ] Create large project performance tests",
        "[ ] Create query performance tests",
        "[ ] Establish performance baselines",
        "[ ] Update CLAUDE.md with testing documentation"
      ]
    }
  }
}
