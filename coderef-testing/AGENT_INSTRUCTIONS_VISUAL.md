# Agent Instructions - Visual Guide

**Context Restored âœ…** | **Phase 1 Complete âœ…** | **Phase 2 Ready to Start â³**

---

## Your Mission (Next 8-10 Hours)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: Framework Detection & Execution (13 Tasks)            â”‚
â”‚                                                                 â”‚
â”‚  Detection (5 tasks)    Execution (8 tasks)    Expected Result  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ DETECT-001       â”‚â†’â†’â†’â”‚ RUN-001          â”‚â†’â†’â†’â”‚ All Tests   â”‚ â”‚
â”‚  â”‚ (pytest)         â”‚   â”‚ (pytest exec)    â”‚   â”‚ Passing âœ…  â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”‚ DETECT-002       â”‚â†’â†’â†’â”‚ RUN-002          â”‚   Framework-      â”‚
â”‚  â”‚ (jest/vitest)    â”‚   â”‚ (jest/vitest)    â”‚   agnostic        â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   results         â”‚
â”‚  â”‚ DETECT-003       â”‚â†’â†’â†’â”‚ RUN-003          â”‚   normalized      â”‚
â”‚  â”‚ (cargo/mocha)    â”‚   â”‚ (cargo/mocha)    â”‚   to unified      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   schema âœ¨       â”‚
â”‚  â”‚ DETECT-004       â”‚â†’â†’â†’â”‚ RUN-004          â”‚                   â”‚
â”‚  â”‚ (caching)        â”‚   â”‚ (parallel exec)  â”‚                   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”‚ DETECT-TEST-001  â”‚â†’â†’â†’â”‚ RUN-005          â”‚                   â”‚
â”‚  â”‚ (unit tests)     â”‚   â”‚ (timeouts)       â”‚                   â”‚
â”‚  â”‚                  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”‚                  â”‚â†’â†’â†’â”‚ RUN-TEST-001     â”‚                   â”‚
â”‚  â”‚                  â”‚   â”‚ (test unit tests)â”‚                   â”‚
â”‚  â”‚                  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”‚                  â”‚â†’â†’â†’â”‚ RUN-TEST-002     â”‚                   â”‚
â”‚  â”‚                  â”‚   â”‚ (pytest integ)   â”‚                   â”‚
â”‚  â”‚                  â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                   â”‚
â”‚  â”‚                  â”‚â†’â†’â†’â”‚ RUN-TEST-003     â”‚                   â”‚
â”‚  â”‚                  â”‚   â”‚ (jest integ)     â”‚                   â”‚
â”‚  â”‚                  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Step-by-Step Execution Path

### Step 1: Start DETECT-001 (Right Now!)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task: DETECT-001 - pytest detection       â”‚
â”‚ Duration: 1 hour                          â”‚
â”‚ Files to Create: src/framework_detector.pyâ”‚
â”‚ Lines of Code: ~250                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Action 1: Mark task as in_progress
  mcp__coderef_workflow__update_task_status(
    project_path="C:\Users\willh\.mcp-servers",
    feature_name="coeref-testing",
    task_id="DETECT-001",
    status="in_progress"
  )

Action 2: Create src/framework_detector.py
  - Implement: async def detect_frameworks(project_path)
  - Implement: async def detect_pytest(project_path)
  - Reference: TESTING_GUIDE.md "Framework Detection"

Action 3: Update server.py handlers
  - handle_discover_tests() â†’ call framework_detector
  - handle_list_frameworks() â†’ call framework_detector

Action 4: Mark task as completed
  mcp__coderef_workflow__update_task_status(
    project_path="C:\Users\willh\.mcp-servers",
    feature_name="coeref-testing",
    task_id="DETECT-001",
    status="completed"
  )
```

### Steps 2-4: Continue Detection (DETECT-002 â†’ DETECT-004)
```
DETECT-002: jest/vitest detection     (1 hour)
  â†’ Add to framework_detector.py
  â†’ Same pattern as pytest

DETECT-003: cargo/mocha detection     (0.75 hours)
  â†’ Add to framework_detector.py
  â†’ Same pattern as pytest

DETECT-004: caching & validation      (0.5 hours)
  â†’ Add @cache decorator
  â†’ Add 1-hour TTL
  â†’ Validate results before returning
```

### Step 5: Test Detection Implementation
```
DETECT-TEST-001: Unit tests            (1 hour)
  â†’ Create tests/test_framework_detector.py
  â†’ Mock filesystem with framework markers
  â†’ Test detection of each framework
  â†’ Test version extraction
  â†’ Test cache behavior

Run tests:
  pytest tests/test_framework_detector.py -v
```

### Step 6: Start Execution (RUN-001)
```
RUN-001: pytest execution              (1.5 hours)
  â†’ Create src/test_runner.py
  â†’ Implement: async def run_pytest(project_path, **kwargs)
  â†’ Use pytest --json-report flag
  â†’ Parse JSON output
  â†’ Convert to UnifiedTestResults
```

### Steps 7-9: Continue Execution (RUN-002 â†’ RUN-003)
```
RUN-002: jest/vitest execution         (1 hour)
  â†’ Add: async def run_jest()
  â†’ Add: async def run_vitest()
  â†’ Use --json flag
  â†’ Same normalization pattern

RUN-003: cargo/mocha execution         (0.75 hours)
  â†’ Add: async def run_cargo()
  â†’ Add: async def run_mocha()
  â†’ Parse custom output formats
```

### Step 10: Advanced Execution Features
```
RUN-004: async/parallel execution      (1.5 hours)
  â†’ Implement asyncio.gather() for parallel runs
  â†’ Use ThreadPoolExecutor for subprocess calls
  â†’ Configurable worker pool size

RUN-005: timeout & error handling      (1 hour)
  â†’ Add: async def execute_with_timeout(cmd, timeout)
  â†’ Catch TimeoutError
  â†’ Catch subprocess errors
  â†’ Return graceful error responses
```

### Steps 11-13: Test the Execution Layer
```
RUN-TEST-001: test_runner unit tests   (1 hour)
  â†’ Create tests/test_runner.py
  â†’ Mock subprocess calls
  â†’ Test schema compliance
  â†’ Test error handling

RUN-TEST-002: pytest integration       (1 hour)
  â†’ Create tests/integration/test_pytest.py
  â†’ Run REAL pytest on sample project
  â†’ Verify results accuracy

RUN-TEST-003: jest integration         (1 hour)
  â†’ Create tests/integration/test_jest.py
  â†’ Run REAL jest on sample project
  â†’ Verify results accuracy
```

---

## File Creation Timeline

```
Hour 1: DETECT-001 (pytest detection)
  â”œâ”€ src/framework_detector.py (start)
  â””â”€ server.py (update 2 handlers)

Hour 2: DETECT-002 (jest/vitest)
  â””â”€ src/framework_detector.py (extend)

Hour 3: DETECT-003 + DETECT-004 (cargo/mocha + caching)
  â””â”€ src/framework_detector.py (finish)

Hour 4: DETECT-TEST-001 (detection tests)
  â”œâ”€ tests/__init__.py (create)
  â”œâ”€ tests/test_framework_detector.py (create)
  â””â”€ Verify tests pass

Hour 5.5: RUN-001 (pytest execution)
  â”œâ”€ src/test_runner.py (start)
  â””â”€ server.py (update 4 execution handlers)

Hour 6.5: RUN-002 (jest/vitest execution)
  â””â”€ src/test_runner.py (extend)

Hour 7.25: RUN-003 (cargo/mocha execution)
  â””â”€ src/test_runner.py (extend)

Hour 8.75: RUN-004 + RUN-005 (parallel + timeout)
  â””â”€ src/test_runner.py (finish)

Hour 9.75: RUN-TEST-001 (test_runner unit tests)
  â””â”€ tests/test_runner.py (create)

Hour 10.75: RUN-TEST-002 + RUN-TEST-003 (integration tests)
  â”œâ”€ tests/integration/__init__.py (create)
  â”œâ”€ tests/integration/test_pytest.py (create)
  â””â”€ tests/integration/test_jest.py (create)

Hour 11: Final testing and fixes
  â”œâ”€ pytest tests/ -v
  â”œâ”€ mypy src/
  â””â”€ Fix any failures
```

---

## The Code You Need to Write

### Framework Detector (250 lines)
```python
# src/framework_detector.py

async def detect_frameworks(project_path: str) -> FrameworkDetectionResult:
    """Main entry point - detect all frameworks"""
    detected = []

    # Check each framework in order
    for detector in [
        detect_pytest,
        detect_jest,
        detect_vitest,
        detect_cargo,
        detect_mocha
    ]:
        result = await detector(project_path)
        if result:
            detected.append(result)

    return FrameworkDetectionResult(
        detected=len(detected) > 0,
        frameworks=detected,
        test_files=[...],
        config_files=[...]
    )

async def detect_pytest(project_path: str) -> Optional[FrameworkInfo]:
    """Check for pytest markers: pyproject.toml, tests/, conftest.py"""
    # Implement

async def detect_jest(project_path: str) -> Optional[FrameworkInfo]:
    """Check for jest markers: package.json, jest.config.js"""
    # Implement

# ... repeat for vitest, cargo, mocha
```

### Test Runner (350 lines)
```python
# src/test_runner.py

async def run_tests(request: TestRunRequest) -> UnifiedTestResults:
    """Execute tests for detected/specified framework"""
    # Auto-detect if needed
    # Call appropriate runner (run_pytest, run_jest, etc)
    # Return UnifiedTestResults

async def run_pytest(project_path: str, **kwargs) -> UnifiedTestResults:
    """Execute pytest and normalize results"""
    # Build: pytest --json-report=report.json
    # Execute with timeout
    # Parse JSON output
    # Return UnifiedTestResults

async def run_jest(project_path: str, **kwargs) -> UnifiedTestResults:
    """Execute jest and normalize results"""
    # Build: jest --json
    # Execute with timeout
    # Parse JSON output
    # Return UnifiedTestResults

# ... repeat for vitest, cargo, mocha
```

---

## Success Metrics by Hour

```
Hour 1  âœ… DETECT-001 complete, framework_detector.py started
Hour 2  âœ… DETECT-002 complete, jest detection working
Hour 3  âœ… DETECT-004 complete, caching implemented
Hour 4  âœ… DETECT-TEST-001 complete, unit tests passing
Hour 5  âœ… RUN-001 complete, pytest execution working
Hour 6  âœ… RUN-002 complete, jest execution working
Hour 7  âœ… RUN-003 complete, cargo/mocha execution working
Hour 8  âœ… RUN-004 + RUN-005 complete, parallel & timeout working
Hour 9  âœ… RUN-TEST-001 complete, test_runner tests passing
Hour 10 âœ… RUN-TEST-002 + RUN-TEST-003 complete, integration tests passing
Hour 11 âœ… All 13 tasks complete, all tests passing, Phase 2 done
```

---

## Decision Tree: What to Do When...

```
Problem: "Don't know how to detect pytest"
â†’ Read TESTING_GUIDE.md "Framework Detection" section
â†’ Look for: pyproject.toml, tests/, conftest.py

Problem: "Tests failing"
â†’ Run: pytest tests/ -v
â†’ Check: stderr for actual error
â†’ Fix: implementation based on error

Problem: "Schema doesn't match"
â†’ Check: UnifiedTestResults in src/models.py
â†’ Verify: all required fields populated
â†’ Reference: example in TESTING_GUIDE.md

Problem: "Don't know next task"
â†’ Check: PHASE_2_QUICKSTART.md checklist
â†’ Next task = first unchecked item
â†’ Mark as in_progress before starting

Problem: "Need to reference something"
â†’ Check: CURRENT_STATUS.md "Key Files to Reference"
â†’ Find: relevant file + section
```

---

## Quick Command Reference

### Task Status
```bash
# Start task
mcp__coderef_workflow__update_task_status(..., status="in_progress")

# Complete task
mcp__coderef_workflow__update_task_status(..., status="completed")
```

### Testing
```bash
# Run all tests
cd C:\Users\willh\.mcp-servers\coderef-testing
pytest tests/ -v

# Run specific test file
pytest tests/test_framework_detector.py -v

# Type checking
mypy src/ --ignore-missing-imports

# Code style
black src/ tests/
ruff check src/ tests/
```

---

## Files You're About to Create

```
âœ“ Phase 1 Files (Already created)
  â”œâ”€ server.py âœ…
  â”œâ”€ src/__init__.py âœ…
  â”œâ”€ src/models.py âœ…
  â””â”€ pyproject.toml âœ…

â†’ Phase 2 Files (You'll create next)
  â”œâ”€ src/framework_detector.py (NEW - 250 lines)
  â”œâ”€ src/test_runner.py (NEW - 350 lines)
  â”œâ”€ tests/__init__.py (NEW - empty)
  â”œâ”€ tests/test_framework_detector.py (NEW - 200 lines)
  â”œâ”€ tests/test_runner.py (NEW - 250 lines)
  â”œâ”€ tests/integration/__init__.py (NEW - empty)
  â”œâ”€ tests/integration/test_pytest.py (NEW - 100 lines)
  â”œâ”€ tests/integration/test_jest.py (NEW - 100 lines)
  â””â”€ server.py (MODIFY - replace placeholder handlers)

= Total Phase 2 Lines = ~1,400 lines of implementation
= Total Project (Phases 1+2) = ~2,800 lines
```

---

## Current Time Investment

```
Phase 1: ~2 hours (âœ… Complete)
Phase 2: ~8-10 hours (â³ Starting now)
Phase 3: ~7-9 hours (â³ After Phase 2)
Phase 4: ~9-11 hours (â³ After Phase 3)

Total: ~27-34 hours

Parallel Speedup: With 4 agents = ~9-11 hours total
Sequential Completion: ~27-34 hours

You are Agent 1 (or continuing solo)
Your work: Phase 2 = 8-10 hours
```

---

## Go! ğŸš€

**Right now:** Read PHASE_2_QUICKSTART.md (2 min)
**Then:** Start DETECT-001 (follow "Start Here" section)
**Every hour:** Mark task completed, move to next task
**After 11 hours:** Phase 2 complete, ready for Phase 3

**You've got this! Phase 1 is done, foundation is solid. Now build the engine.** âš™ï¸

---

Last Updated: 2025-12-27
Workorder: WO-COEREF-TESTING-001
Ready: YES âœ…
