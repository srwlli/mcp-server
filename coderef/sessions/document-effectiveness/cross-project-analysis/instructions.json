{
  "workorder_id": "WO-DOCUMENT-EFFECTIVENESS-002",
  "task": "Cross-Project Document Analysis - Identify Universal Patterns",
  "step": 2,
  "description": "CodeRef orchestrator agent synthesizes all value audits to identify patterns that work across all projects",
  "depends_on": "WO-DOCUMENT-EFFECTIVENESS-001 (value audits complete)",
  "assigned_to": "coderef agent (C:\\Users\\willh\\.mcp-servers\\coderef)",

  "instructions": {
    "step_1": "READ all value audit reports from sessions/document-effectiveness/value-audit/",
    "step_2": "IDENTIFY common patterns across all 9 agent projects",
    "step_3": "EXTRACT what works universally vs. what's project-specific",
    "step_4": "ANALYZE gaps - what's missing everywhere?",
    "step_5": "CREATE synthesis report at output path below",
    "step_6": "PROVIDE evidence from multiple agents for each finding"
  },

  "analysis_dimensions": {
    "universal_winners": {
      "description": "Document types that work well across ALL projects",
      "criteria": "Avg rating >= 4.0/5, used by >= 7/9 agents",
      "output": "List of gold-standard doc types to keep and expand"
    },
    "universal_losers": {
      "description": "Document types that underperform everywhere",
      "criteria": "Avg rating <= 2.5/5 across multiple projects",
      "output": "List of doc types to retire or radically redesign"
    },
    "context_dependent": {
      "description": "Document types that work in some contexts but not others",
      "criteria": "High variance in ratings (std dev > 1.5)",
      "output": "Conditional recommendations (when to use, when to skip)"
    },
    "universal_gaps": {
      "description": "Missing doc types requested by multiple agents",
      "criteria": "Mentioned by >= 3/9 agents as 'missing'",
      "output": "New document types to create"
    },
    "format_patterns": {
      "description": "Structural patterns that correlate with high ratings",
      "criteria": "Common elements in 4.5+/5 rated docs",
      "output": "Document design principles"
    }
  },

  "output_template": "# Cross-Project Document Analysis\n\n**Workorder:** WO-DOCUMENT-EFFECTIVENESS-002\n**Data Sources:** 9 agent value audits\n**Timestamp:** {current_timestamp}\n\n---\n\n## Executive Summary\n\n**Universal Winners (Keep & Expand):**\n1. CLAUDE.md (4.7/5 avg) - Used by 9/9 agents\n2. .coderef/index.json (4.5/5 avg) - Used by 8/9 agents\n3. plan.json (4.3/5 avg) - Used by 7/9 agents\n\n**Universal Losers (Retire or Redesign):**\n1. README.md (2.1/5 avg) - Too minimal across all projects\n2. Deprecated tracking files (1.5/5 avg) - Noise\n\n**Universal Gaps (Create):**\n1. QUICKREF.md - Requested by 6/9 agents\n2. CHANGELOG.md - Missing in 7/9 projects\n3. TROUBLESHOOTING.md - Requested by 4/9 agents\n\n**Key Insight:** Agent-facing docs are excellent, human-facing docs are critically weak across the ecosystem.\n\n---\n\n## Universal Winners\n\n### CLAUDE.md\n\n**Average Rating:** 4.7/5 (agent), 4.2/5 (human)\n**Usage:** 9/9 projects\n**Consistency:** High (all follow similar template)\n\n**What Makes It Work:**\n- Predictable structure (Quick Summary, Problem, Architecture, Workflows)\n- Comprehensive role documentation\n- Recent changes section\n- Design decisions captured\n- Machine-parseable sections\n\n**Evidence from Agents:**\n- coderef-workflow: \"5/5 - Critical for understanding my orchestration role\"\n- coderef-docs: \"5/5 - Best source for AI generator context\"\n- assistant: \"4.8/5 - Missing quick-start examples only\"\n\n**Recommendation:** **Keep and standardize further.** Make CLAUDE.md template mandatory for all new projects.\n\n---\n\n### .coderef/index.json\n\n**Average Rating:** 4.5/5 (agent), 2.0/5 (human)\n**Usage:** 8/9 projects (coderef-dashboard pending)\n**Consistency:** Very high (generated by same tool)\n\n**What Makes It Work:**\n- Comprehensive code inventory\n- 99% AST accuracy\n- Consistent schema\n- Auto-generated (always fresh)\n- Machine-readable\n\n**Evidence from Agents:**\n- coderef-context: \"5/5 - My primary output, high utilization\"\n- coderef-workflow: \"5/5 - First source I check during planning\"\n- coderef-docs: \"4/5 - Use for foundation doc generation\"\n\n**Recommendation:** **Keep and expand.** Add human-readable companion (context.md is good start).\n\n---\n\n## Universal Losers\n\n### README.md\n\n**Average Rating:** 2.1/5 (agent), 2.1/5 (human)\n**Usage:** 9/9 projects (but all underutilized)\n**Consistency:** Low (wildly different formats/completeness)\n\n**What Doesn't Work:**\n- Too minimal (\"just project name and 1 sentence\")\n- Stale (last updated 6+ months ago)\n- No examples or usage instructions\n- Missing standard sections (Installation, API Reference)\n\n**Evidence from Agents:**\n- assistant: \"2/5 - Too minimal for onboarding\"\n- coderef-system: \"2/5 - Doesn't reflect current CLI commands\"\n- coderef-dashboard: \"2.5/5 - No setup instructions\"\n\n**Recommendation:** **Radically expand using standard template.** Auto-generate from .coderef/ where possible.\n\n---\n\n## Universal Gaps\n\n### QUICKREF.md (Missing in 9/9 projects)\n\n**Requested By:** 6/9 agents\n**Purpose:** 1-2 page scannable reference for quick lookups\n\n**Agent Requests:**\n- coderef-workflow: \"Need quick command reference\"\n- coderef-docs: \"Users ask 'what tools exist?' - need 1-pager\"\n- assistant: \"Handoff prompts would benefit from quickref\"\n\n**Recommendation:** **Create standardized QUICKREF.md template.** 150-250 lines, scannable, updated automatically.\n\n### CHANGELOG.md (Missing in 7/9 projects)\n\n**Requested By:** 5/9 agents\n**Purpose:** Track version history and breaking changes\n\n**Agent Requests:**\n- coderef-docs: \"No way to track what changed between versions\"\n- papertrail: \"UDS compliance requires changelog\"\n\n**Recommendation:** **Create and mandate CHANGELOG.md.** Use conventional commits for auto-generation.\n\n---\n\n## Format Patterns (What Makes Docs Work)\n\n**High-rated documents (4.5+/5) share these characteristics:**\n\n1. **Predictable Structure**\n   - Same sections in same order\n   - Clear hierarchy (## for major, ### for minor)\n   - Table of contents for long docs\n\n2. **Machine + Human Readable**\n   - JSON for agents (.coderef/, plan.json)\n   - Markdown for humans (CLAUDE.md, README)\n   - Hybrid (DELIVERABLES.md with both)\n\n3. **Examples Over Theory**\n   - Show, don't tell\n   - Code snippets\n   - Before/after comparisons\n\n4. **Freshness Indicators**\n   - \"Last Updated\" timestamp\n   - Version number\n   - Recent changes section\n\n5. **Cross-References**\n   - \"See also\" sections\n   - Hyperlinks to related docs\n   - Clear document hierarchy\n\n---\n\n## Recommendations by Impact\n\n### Critical (Ecosystem-Wide)\n\n1. **Standardize CLAUDE.md template** - Make mandatory, auto-validate\n2. **Create QUICKREF.md standard** - 1-2 page scannable reference\n3. **Expand README.md template** - Installation, usage, examples\n4. **Add CHANGELOG.md** - Track version history\n\n### High (Most Projects)\n\n5. **Integrate standards docs** - Link patterns.md to workflows\n6. **Add architecture diagrams** - Visual flow in ARCHITECTURE.md\n7. **Create TROUBLESHOOTING.md** - Common issues and fixes\n\n### Medium (Some Projects)\n\n8. **CONTRIBUTING.md** - For open-source projects\n9. **API docs auto-generation** - From .coderef/ outputs\n10. **Doc freshness automation** - Auto-update timestamps\n\n---\n\n## Next Phase: Improvement Roadmap\n\nWith these findings, we can now create a concrete implementation plan:\n\n1. **Template creation** - Standardized templates for QUICKREF, expanded README, CHANGELOG\n2. **Auto-generation** - Use .coderef/ to populate templates\n3. **Validation** - Pre-commit hooks to ensure docs meet standards\n4. **Migration** - Roll out to all 9 projects systematically\n\n---\n\n**Confidence Level:** High - Based on 9 independent agent audits with consistent findings\n**Risk Level:** Low - All recommendations are additive (no deletions of critical files)",

  "quality_standards": {
    "evidence_based": "Every finding must cite multiple agents",
    "quantitative": "Use averages, counts, percentages",
    "actionable": "Lead directly to concrete improvements",
    "balanced": "Consider agent and human perspectives equally"
  },

  "output_file": "C:\\Users\\willh\\.mcp-servers\\coderef\\sessions\\document-effectiveness\\cross-project-analysis\\synthesis-report.md"
}
