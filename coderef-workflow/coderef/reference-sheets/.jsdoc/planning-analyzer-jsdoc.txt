# JSDoc Suggestions for planning_analyzer.py

## Purpose
Copy-paste JSDoc comments to enhance inline documentation in planning_analyzer.py

## Usage Instructions
1. Copy the relevant JSDoc block below
2. Paste above the corresponding function/class in planning_analyzer.py
3. Adjust parameter names/types if implementation differs

---

## Module-Level Documentation

```python
"""
Planning Analyzer Generator for MCP Planning Workflow System.

Analyzes projects to discover foundation docs, coding standards, reference components,
and patterns. Automates section 0 (Preparation) of implementation plans.

**Core Innovation (v1.3.0):**
Integrated with .coderef/ pre-scanned structure for 5-10x faster planning.
Reads .coderef/index.json, patterns.json, coverage.json instead of live scanning.

**3-Tier Fallback System:**
1. Read .coderef/ pre-scanned data (fastest, 5-10x speedup)
2. Call coderef-context MCP tools (medium speed, live scan)
3. Regex-based filesystem analysis (slowest, fallback)

**Returns:** PreparationSummaryDict with 9 analysis components for plan.json Section 0

**Performance:**
- With .coderef/: 5-10 seconds (reads pre-scanned data)
- Without .coderef/: 30-60 seconds (live filesystem + MCP)

**Dependencies:**
- coderef-context MCP server (optional for live scanning)
- .coderef/ structure (preferred for pre-scanned data)
- mcp_client.py (async MCP communication)
- coderef/utils (wrapper functions for .coderef/ access)

**Version:** 1.3.0
**See:** PLANNING-ANALYZER.md for complete documentation
**Maintained by:** willh, Claude Code AI
"""
```

---

## Class Definition

```python
class PlanningAnalyzer:
    """
    Analyzes projects for implementation planning preparation.

    Scans project directory to discover:
    - Foundation documentation (API.md, ARCHITECTURE.md, etc.)
    - Coding standards (BEHAVIOR-STANDARDS.md, etc.)
    - Reference components (similar files/patterns)
    - Key patterns (error handling, naming conventions)
    - Technology stack (language, framework, database, testing)
    - Project structure (organization pattern)
    - Gaps and risks (missing docs, standards, tests, CI)

    **State Ownership:**
    - Owns: project_path (constructor argument)
    - Returns: PreparationSummaryDict (ephemeral, not cached)
    - Stateless: No persistent state, compute fresh on each analyze()

    **Lifecycle:**
    1. __init__(project_path) → Sets self.project_path
    2. analyze() → Orchestrates 9 scanner methods
    3. Returns PreparationSummaryDict → Used by PlanningGenerator

    **Performance:**
    - With .coderef/: ~5-10 seconds (5-10x faster)
    - Without .coderef/: ~30-60 seconds

    **Example:**
        >>> analyzer = PlanningAnalyzer(Path("/path/to/project"))
        >>> analysis = await analyzer.analyze()
        >>> analysis['foundation_docs']
        {'available': ['README.md (root)', ...], 'missing': ['API.md', ...]}

    **See:** PLANNING-ANALYZER.md Section 3 for architecture details
    """
```

---

## Constructor

```python
def __init__(self, project_path: Path):
    """
    Initialize PlanningAnalyzer with project path.

    **Args:**
        project_path (Path): Absolute path to project directory to analyze

    **Side Effects:**
        - Sets self.project_path
        - Logs initialization message

    **Performance:** <1ms

    **Example:**
        >>> from pathlib import Path
        >>> analyzer = PlanningAnalyzer(Path("/path/to/my-project"))
        >>> analyzer.project_path
        PosixPath('/path/to/my-project')

    **See:** PLANNING-ANALYZER.md Section 4.1
    """
```

---

## Main Analysis Method

```python
async def analyze(self) -> PreparationSummaryDict:
    """
    Main analysis method - orchestrates all scanning operations.

    **Workflow:**
    1. Check .coderef/ freshness (warn if >10% drift)
    2. Scan foundation docs (README, ARCHITECTURE, etc.)
    3. Read foundation doc content (extract headers, preview)
    4. Read inventory data (.coderef/ → MCP → filesystem)
    5. Scan coding standards (BEHAVIOR-STANDARDS.md, etc.)
    6. Find reference components (similar files)
    7. Identify patterns (.coderef/ → MCP → regex)
    8. Detect technology stack (package.json, requirements.txt)
    9. Analyze project structure (directory organization)
    10. Identify gaps and risks (.coderef/ → MCP → manual)

    **Async:** Yes (uses await for MCP tool calls)

    **Returns:**
        PreparationSummaryDict: Complete analysis with 9 components:
            - foundation_docs: {'available': [...], 'missing': [...]}
            - foundation_doc_content: {'ARCHITECTURE.md': {...}, ...}
            - inventory_data: {'endpoints': [...], 'schemas': [...], ...}
            - coding_standards: {'available': [...], 'missing': [...]}
            - reference_components: ['file1.py', 'file2.py', ...]
            - key_patterns_identified: ['Pattern 1', 'Pattern 2', ...]
            - technology_stack: {'language': '...', 'framework': '...', ...}
            - project_structure: {'pattern': '...', 'depth': N, ...}
            - gaps_and_risks: ['Gap 1', 'Gap 2', ...]

    **Performance:**
        - With .coderef/: 5-10 seconds (reads pre-scanned data)
        - Without .coderef/: 30-60 seconds (live scanning + MCP calls)

    **Side Effects:**
        - Logs progress for each scanner method
        - Logs warning if .coderef/ >10% stale
        - Logs total duration at end

    **Example:**
        >>> analyzer = PlanningAnalyzer(Path("/path/to/project"))
        >>> analysis = await analyzer.analyze()
        >>> len(analysis)
        9
        >>> analysis['technology_stack']['language']
        'Python'

    **See:**
        - PLANNING-ANALYZER.md Section 4.2
        - type_defs.py:PreparationSummaryDict for return type definition
    """
```

---

## Freshness Check (v1.3.0)

```python
def check_coderef_freshness(self) -> str | None:
    """
    Check if .coderef/ data is stale by reading drift.json.

    **Purpose:** Warns user if pre-scanned data is >10% outdated

    **Logic:**
        drift_percent = (changed_files / total_files) * 100
        if drift_percent > 10:
            return warning_message

    **Returns:**
        str | None:
            - str: Warning message if >10% drift detected
            - None: If fresh (<10% drift) or no drift.json found

    **Performance:** <5ms (single file read)

    **Example:**
        >>> analyzer = PlanningAnalyzer(Path("/path/to/project"))
        >>> warning = analyzer.check_coderef_freshness()
        >>> if warning:
        ...     print(warning)
        ⚠️ .coderef/ data is stale (15.3% drift detected).
        Consider re-running 'coderef scan /path/to/project' for accurate analysis.

    **Action Required:**
        If warning returned, user should:
        1. Run: coderef scan /path/to/project
        2. Re-run planning workflow

    **Added:** v1.3.0 (WO-CODEREF-INTEGRATION-001)
    **See:** PLANNING-ANALYZER.md Section 4.3
    """
```

---

## Foundation Docs Scanner

```python
def scan_foundation_docs(self) -> dict:
    """
    Scans for foundation documentation files.

    **Checks For:**
        - README.md
        - API.md
        - ARCHITECTURE.md
        - COMPONENTS.md
        - SCHEMA.md
        - USER-GUIDE.md

    **Search Locations:**
        1. Project root (project_path/)
        2. coderef/foundation-docs/

    **Returns:**
        dict: {'available': [...], 'missing': [...]}
            - available: List of found docs with location
              Example: ['README.md (root)', 'ARCHITECTURE.md (coderef/foundation-docs)']
            - missing: List of missing doc names
              Example: ['API.md', 'COMPONENTS.md']

    **Performance:** ~10ms (checks 12 file paths: 6 docs × 2 locations)

    **Example:**
        >>> analyzer = PlanningAnalyzer(project_path)
        >>> result = analyzer.scan_foundation_docs()
        >>> result['available']
        ['README.md (root)', 'ARCHITECTURE.md (coderef/foundation-docs)']
        >>> result['missing']
        ['API.md', 'COMPONENTS.md', 'SCHEMA.md', 'USER-GUIDE.md']

    **See:** PLANNING-ANALYZER.md Section 4.4
    """
```

---

## Foundation Doc Content Reader

```python
def read_foundation_doc_content(self) -> dict:
    """
    Read and extract key content from foundation docs.

    **Reads:** ARCHITECTURE.md, API.md, COMPONENTS.md, SCHEMA.md, README.md

    **Extracts:**
        - location: 'root' or 'coderef/foundation-docs'
        - preview: First 500 characters
        - headers: First 10 markdown headers (via _extract_headers())
        - size: Total character count

    **Returns:**
        dict: Mapping of doc name to content info
            {
                'ARCHITECTURE.md': {
                    'location': 'root',
                    'preview': '# Architecture\n\nThis project...',
                    'headers': ['Architecture', 'Overview', 'Components', ...],
                    'size': 15234
                },
                ...
            }

    **Performance:** ~50-100ms (reads 5 files, each ~10-50KB)

    **Example:**
        >>> content = analyzer.read_foundation_doc_content()
        >>> arch = content.get('ARCHITECTURE.md')
        >>> arch['headers']
        ['Architecture', 'Overview', 'Components', 'Data Flow']
        >>> len(arch['preview'])
        500

    **See:**
        - PLANNING-ANALYZER.md Section 4.5
        - _extract_headers() helper method
    """
```

---

## Header Extraction Helper

```python
def _extract_headers(self, content: str) -> List[str]:
    """
    Extract markdown headers from content.

    **Implementation:**
        Uses regex: r'^#{1,3}\s+(.+)$'
        Matches H1, H2, H3 headers only (ignores H4+)

    **Args:**
        content (str): Markdown content to parse

    **Returns:**
        List[str]: First 10 header titles (without # prefix)

    **Example:**
        >>> content = "# Title\n## Section 1\n### Subsection\n## Section 2"
        >>> analyzer._extract_headers(content)
        ['Title', 'Section 1', 'Subsection', 'Section 2']

    **Performance:** ~5ms (regex on typical 50KB markdown file)

    **Limitations:**
        - Only matches H1-H3 (not H4, H5, H6)
        - Limits to first 10 headers
        - Does not validate markdown syntax

    **See:** read_foundation_doc_content() for usage context
    """
```

---

## Inventory Data Reader (3-Tier Fallback)

```python
async def read_inventory_data(self) -> dict:
    """
    Read existing inventory data from .coderef/index.json or generate live inventory.

    **3-Tier Fallback System:**
    1. Read .coderef/index.json (fastest - pre-scanned data)
    2. Call coderef_scan MCP tool (medium - live scan)
    3. Return empty inventory (fallback - graceful degradation)

    **Tier 1 Implementation:**
        if check_coderef_available(project_path, 'index.json'):
            data = read_coderef_output(project_path, 'index.json')
            return parse_inventory(data)

    **Tier 2 Implementation:**
        try:
            result = await call_coderef_tool('coderef_scan', {...})
            return result.get('data', {})
        except Exception as e:
            logger.debug(f"coderef_scan unavailable: {e}")

    **Tier 3 Implementation:**
        return {'endpoints': [], 'schemas': [], 'dependencies': []}

    **Async:** Yes (Tier 2 uses MCP client)

    **Returns:**
        dict: Inventory with endpoints, schemas, dependencies
            {
                'endpoints': ['GET /api/users', 'POST /api/auth', ...],
                'schemas': ['User', 'AuthToken', ...],
                'dependencies': ['fastapi', 'pydantic', ...]
            }

    **Performance:**
        - Tier 1: ~5ms (file read)
        - Tier 2: ~500ms (MCP call)
        - Tier 3: <1ms (returns empty dict)

    **Example:**
        >>> inventory = await analyzer.read_inventory_data()
        >>> inventory['endpoints']
        ['GET /api/users', 'POST /api/auth/login']

    **See:**
        - PLANNING-ANALYZER.md Section 4.6
        - coderef/utils:check_coderef_available
        - coderef/utils:read_coderef_output
    """
```

---

## Pattern Identifier (2-Tier Fallback)

```python
async def identify_patterns(self) -> list:
    """
    Identifies coding patterns from .coderef/reports/patterns.json or regex analysis.

    **2-Tier Fallback System:**
    1. Read .coderef/reports/patterns.json (fastest)
    2. Call coderef_patterns MCP tool (medium)
    3. Regex-based filesystem analysis (slowest, fallback)

    **Tier 1 Implementation:**
        if check_coderef_available(project_path, 'reports/patterns.json'):
            patterns_data = read_coderef_output(project_path, 'reports/patterns.json')
            return [p['pattern'] for p in patterns_data['patterns'][:15]]

    **Tier 2 Implementation:**
        result = await call_coderef_tool('coderef_patterns', {...})
        return [str(p) for p in result.get('patterns', [])[:15]]

    **Tier 3 Implementation (Regex Fallback):**
        Scans first 200 source files for:
        - Error handling: try-catch, throw new Error
        - File organization: export from
        - Naming conventions: camelCase, UPPER_SNAKE_CASE

    **Async:** Yes (Tier 2 uses MCP client)

    **Returns:**
        list[str]: List of pattern descriptions (max 15)
            [
                'Error handling: try-catch blocks found in 45 files',
                'Naming: camelCase for functions (120/150 functions)',
                'File organization: barrel exports found in 30 files',
                ...
            ]

    **Performance:**
        - Tier 1: ~5ms (file read)
        - Tier 2: ~500ms (MCP call)
        - Tier 3: ~2-5s (scans 200 files with regex)

    **Example:**
        >>> patterns = await analyzer.identify_patterns()
        >>> patterns[0]
        'Error handling: try-catch blocks found in 45 files'

    **Added:** v1.3.0 integration with .coderef/
    **See:**
        - PLANNING-ANALYZER.md Section 4.9
        - _scan_source_files() for Tier 3 file discovery
    """
```

---

## Gaps & Risks Identifier (2-Tier Fallback)

```python
async def identify_gaps_and_risks(self) -> list:
    """
    Identifies missing documentation, test coverage, CI/CD.

    **2-Tier Fallback System:**
    1. Read .coderef/reports/coverage.json (fastest)
    2. Call coderef_coverage MCP tool (medium)
    3. Manual analysis (fallback)

    **Tier 1 Implementation:**
        if check_coderef_available(project_path, 'reports/coverage.json'):
            coverage_data = read_coderef_output(project_path, 'reports/coverage.json')
            if coverage_data.get('coverage_percent', 100) < 70:
                gaps.append(f"Low test coverage ({coverage_percent}%)")

    **Checks:**
        - Test coverage <70%
        - Missing foundation docs (README, ARCHITECTURE, etc.)
        - Missing coding standards (UI-PATTERNS.md, etc.)
        - No CI/CD configuration (.github/workflows/, .gitlab-ci.yml)
        - No .gitignore file
        - No type checking (tsconfig.json, mypy.ini)

    **Async:** Yes (Tier 2 uses MCP client)

    **Returns:**
        list[str]: List of gaps and risks
            [
                'Low test coverage (45% coverage)',
                'Missing foundation docs: API.md, COMPONENTS.md',
                'Missing coding standards: UI-PATTERNS.md',
                'No CI/CD configuration detected',
                'No type checking configuration found'
            ]

    **Performance:**
        - Tier 1: ~5ms (file read)
        - Tier 2: ~500ms (MCP call)
        - Tier 3: ~100ms (manual file checks)

    **Example:**
        >>> gaps = await analyzer.identify_gaps_and_risks()
        >>> gaps
        ['Low test coverage (45%)', 'Missing foundation docs: API.md']

    **Added:** v1.3.0 integration with .coderef/
    **See:** PLANNING-ANALYZER.md Section 4.12
    """
```

---

## Technology Stack Detector

```python
def detect_technology_stack(self) -> dict:
    """
    Identifies technology stack from indicator files.

    **Checks For:**
        - package.json → Node.js/TypeScript (reads dependencies)
        - requirements.txt → Python (parses packages)
        - pyproject.toml → Python (reads tool.poetry.dependencies)
        - go.mod → Go
        - Cargo.toml → Rust

    **Extracts:**
        - Language (JavaScript, TypeScript, Python, Go, Rust)
        - Framework (React, Next.js, FastAPI, Flask, etc.)
        - Database (PostgreSQL, MongoDB, SQLite, etc.)
        - Testing (Jest, pytest, vitest, etc.)
        - Build system (Webpack, Vite, tsc, uv, etc.)

    **Returns:**
        dict: Technology stack information
            {
                'language': 'Python',
                'framework': 'FastAPI',
                'database': 'PostgreSQL',
                'testing': 'pytest',
                'build': 'uv'
            }

    **Performance:** ~50-100ms (reads 1-2 files, parses JSON/TOML)

    **Example:**
        >>> tech = analyzer.detect_technology_stack()
        >>> tech['language']
        'Python'
        >>> tech['framework']
        'FastAPI'

    **Detection Logic:**
        - Checks for dependency names in package.json/requirements.txt
        - Infers framework from common patterns (e.g., 'fastapi' → FastAPI)
        - Returns 'unknown' if no indicator files found

    **See:** PLANNING-ANALYZER.md Section 4.10
    """
```

---

## Project Structure Analyzer

```python
def analyze_project_structure(self) -> dict:
    """
    Analyzes directory organization pattern.

    **Detects:**
        - Monorepo (has packages/ or apps/)
        - Feature-based (has features/ directory)
        - Domain-driven (has domain/ directory)
        - Layered (has controllers/, services/, models/)
        - Flat (all files in root or single directory)

    **Returns:**
        dict: Structure information
            {
                'pattern': 'layered',  # or 'monorepo', 'feature-based', etc.
                'depth': 4,  # max directory nesting
                'top_level_dirs': ['src', 'tests', 'docs', 'scripts']
            }

    **Performance:** ~20-50ms (scans top 2 directory levels)

    **Example:**
        >>> structure = analyzer.analyze_project_structure()
        >>> structure['pattern']
        'layered'
        >>> structure['top_level_dirs']
        ['src', 'tests', 'docs']

    **Detection Priority:**
        1. Monorepo (highest confidence)
        2. Feature-based
        3. Domain-driven
        4. Layered
        5. Flat (default)

    **See:** PLANNING-ANALYZER.md Section 4.11
    """
```

---

## Source Files Scanner (Helper)

```python
def _scan_source_files(self) -> list[Path]:
    """
    Recursively scans for source files, respects EXCLUDE_DIRS.

    **Excluded Directories:**
        - node_modules
        - .git
        - __pycache__
        - dist, build
        - .venv, venv

    **Allowed Extensions:**
        .py, .js, .ts, .jsx, .tsx, .go, .rs

    **Returns:**
        list[Path]: List of Path objects for all source files

    **Performance:** ~500ms-2s (depends on project size)

    **Example:**
        >>> files = analyzer._scan_source_files()
        >>> len(files)
        245
        >>> files[0]
        PosixPath('/path/to/project/src/main.py')

    **Usage:**
        Called by identify_patterns() Tier 3 fallback
        Called by find_reference_components()

    **See:**
        - constants.py:EXCLUDE_DIRS
        - constants.py:ALLOWED_FILE_EXTENSIONS
    """
```

---

## Configuration Best Practices

**Using PlanningAnalyzer:**
```python
# Always await async methods
analyzer = PlanningAnalyzer(project_path)
analysis = await analyzer.analyze()  # ✅ Correct

# Don't forget await
analysis = analyzer.analyze()  # ❌ Returns coroutine, not dict

# Check freshness before analysis
warning = analyzer.check_coderef_freshness()
if warning:
    print(warning)
    # User should re-run: coderef scan /path/to/project

# Use with PlanningGenerator
generator = PlanningGenerator(project_path)
plan = await generator.generate_plan(context, analysis)
```

**Performance Optimization:**
```python
# 1. Pre-generate .coderef/ for 5-10x speedup
# Run before planning workflow:
# $ coderef scan /path/to/project

# 2. Check drift before analysis
analyzer = PlanningAnalyzer(project_path)
drift_warning = analyzer.check_coderef_freshness()

if drift_warning:
    # Re-generate .coderef/ if >10% stale
    # $ coderef scan /path/to/project
    pass

# 3. Cache analysis results
analysis = await analyzer.analyze()
analysis_json = project_path / 'coderef' / 'workorder' / feature_name / 'analysis.json'
analysis_json.write_text(json.dumps(analysis, indent=2))
```

**Error Handling:**
```python
try:
    analysis = await analyzer.analyze()
except Exception as e:
    logger.error(f"Analysis failed: {e}")
    # Falls back gracefully - returns default values
    # Check logs for tier failures
```

---

**Generated by:** Resource Sheet MCP Tool v1.0
**Workorder:** WO-RESOURCE-SHEET-P0-001
**Task:** SHEET-003
**Timestamp:** 2026-01-02
