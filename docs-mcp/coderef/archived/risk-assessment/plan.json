{
  "META_DOCUMENTATION": {
    "feature_name": "risk-assessment",
    "version": "1.0.0",
    "status": "complete",
    "generated_by": "Lloyd (AI Coordinator)",
    "generated_at": "2025-10-23",
    "has_context": true,
    "has_analysis": true,
    "workorder_id": "WO-RISK-ASSESSMENT-001",
    "estimated_complexity": "high",
    "estimated_duration": "5-7 days"
  },
  "UNIVERSAL_PLANNING_STRUCTURE": {
    "0_preparation": {
      "foundation_docs_available": [
        "README.md - Project overview",
        "USER-GUIDE.md - Tool usage documentation"
      ],
      "foundation_docs_missing": [
        "ARCHITECTURE.md - System design",
        "API.md - API reference",
        "COMPONENTS.md - Component catalog"
      ],
      "coding_standards_available": [],
      "coding_standards_missing": [
        "Must infer from existing tool_handlers.py patterns"
      ],
      "reference_components": [
        "tool_handlers.py:handle_analyze_project_for_planning - Project analysis pattern",
        "generators/audit_generator.py - Scoring and assessment pattern",
        "validation.py - Input validation patterns",
        "error_responses.py - Error handling",
        "handler_decorators.py - @mcp_error_handler pattern"
      ],
      "technology_stack": {
        "language": "Python 3.11+",
        "framework": "Flask (MCP server)",
        "testing": "pytest",
        "dependencies": "pathlib, json, datetime, typing",
        "file_handling": "pathlib.Path for cross-platform"
      },
      "project_structure": {
        "tool_definitions": "server.py (register assess_risk tool)",
        "tool_handlers": "tool_handlers.py (add handle_assess_risk)",
        "generators": "generators/risk_generator.py (new - risk analysis logic)",
        "risk_assessments": "coderef/risk-assessments/ (new directory)",
        "validation": "validation.py (add risk input validation)",
        "tests": "tests/unit/handlers/test_risk_handler.py"
      },
      "key_patterns_identified": [
        "@mcp_error_handler decorator for all handlers",
        "format_success_response() for consistent returns",
        "pathlib.Path for file operations",
        "TypedDict for structured returns",
        "ErrorResponse factory for errors",
        "Validation at MCP boundaries"
      ],
      "gaps_and_risks": [
        "No formal risk scoring precedent - need to design algorithm",
        "Multi-option comparison complexity",
        "Performance constraint (5 second limit)",
        "Graceful degradation for missing context",
        "Deterministic scoring requirement"
      ]
    },
    "1_executive_summary": {
      "feature_name": "AI-Powered Risk Assessment",
      "description": "AI-powered risk assessment workflow that evaluates proposed code changes, file modifications, or deployment decisions. Provides structured risk analysis with severity ratings, likelihood scores, and actionable recommendations. Supports multi-option comparison and generates machine-readable JSON output.",
      "business_value": "Enable AI agents and developers to make informed decisions before code changes, reducing bugs, security issues, and breaking changes. Reduces decision time from 10-20 minutes to under 5 seconds with structured, repeatable risk evaluation.",
      "user_story": "As an AI agent proposing code changes, I want to evaluate risks across multiple dimensions (breaking changes, security, performance, maintainability, reversibility) so that I can make informed go/no-go decisions and present clear recommendations to users.",
      "target_audience": "AI agents in multi-agent workflows, human developers evaluating complex changes",
      "success_metrics": [
        "Risk evaluation completes in < 5 seconds",
        "80%+ accuracy in identifying high-risk changes",
        "Supports comparison of 3+ alternative approaches",
        "100% machine-parseable JSON output"
      ]
    },
    "2_risk_assessment": {
      "complexity_score": 8,
      "complexity_explanation": "High complexity due to multi-dimensional risk analysis, scoring algorithm design, multi-option comparison, performance constraints, and need for deterministic results. Requires sophisticated project analysis and intelligent risk detection.",
      "technical_risks": [
        {
          "risk": "Scoring algorithm not deterministic or explainable",
          "likelihood": "medium",
          "impact": "high",
          "mitigation": "Design clear scoring matrix, use explicit weights, extensive unit testing, document algorithm"
        },
        {
          "risk": "Performance exceeds 5 second limit",
          "likelihood": "medium",
          "impact": "medium",
          "mitigation": "Implement timeout handling, optimize file reading, cache analysis results, profile performance"
        },
        {
          "risk": "Missing context causes inaccurate risk assessment",
          "likelihood": "high",
          "impact": "medium",
          "mitigation": "Graceful degradation, confidence scoring, clearly indicate when context is incomplete"
        },
        {
          "risk": "Multi-option comparison becomes exponentially complex",
          "likelihood": "low",
          "impact": "medium",
          "mitigation": "Limit to 5 options max, reuse analysis across options, parallel evaluation where possible"
        }
      ],
      "dependencies": [
        "analyze_project_for_planning pattern (existing)",
        "Path validation and security (existing)",
        "JSON schema design (new)",
        "Risk scoring algorithm (new)"
      ],
      "assumptions": [
        "Project has readable source files",
        "Git history is available (optional)",
        "Proposed changes are described clearly",
        "Risk dimensions are universal (breaking, security, performance, maintainability, reversibility)"
      ]
    },
    "3_current_state_analysis": {
      "files_to_create": [
        "generators/risk_generator.py - Main risk assessment logic",
        "coderef/risk-assessments/ - Output directory",
        "tests/unit/handlers/test_risk_handler.py - Unit tests",
        "templates/risk/assessment-schema.json - JSON schema"
      ],
      "files_to_modify": [
        "server.py - Register assess_risk tool",
        "tool_handlers.py - Add handle_assess_risk",
        "validation.py - Add risk input validation",
        "constants.py - Add RISK_ASSESSMENTS_DIR constant",
        "type_defs.py - Add RiskAssessment TypedDict"
      ],
      "files_to_read": [
        "generators/audit_generator.py - Reference for scoring patterns",
        "tool_handlers.py:handle_analyze_project_for_planning - Project analysis",
        "validation.py - Existing validation patterns"
      ],
      "integration_points": [
        "MCP tool registration in server.py",
        "Handler registry in tool_handlers.py",
        "Validation layer in validation.py",
        "Optional integration with /create-plan for pre-flight risk checks"
      ]
    },
    "4_key_features": [
      {
        "feature_id": "RISK-001",
        "name": "Risk Input Validation",
        "description": "Validate proposed changes input: file paths, descriptions, change types, options",
        "priority": "critical",
        "estimated_effort": "small"
      },
      {
        "feature_id": "RISK-002",
        "name": "Project Context Analysis",
        "description": "Analyze project files, dependencies, patterns to build risk evaluation context",
        "priority": "critical",
        "estimated_effort": "medium"
      },
      {
        "feature_id": "RISK-003",
        "name": "Multi-Dimensional Risk Evaluation",
        "description": "Evaluate 5 risk dimensions: breaking changes, security, performance, maintainability, reversibility",
        "priority": "critical",
        "estimated_effort": "large"
      },
      {
        "feature_id": "RISK-004",
        "name": "Risk Scoring Algorithm",
        "description": "Calculate deterministic risk scores: severity (low/medium/high/critical) x likelihood (0-100%) = score (0-100)",
        "priority": "critical",
        "estimated_effort": "large"
      },
      {
        "feature_id": "RISK-005",
        "name": "Multi-Option Comparison",
        "description": "Support comparison of multiple alternative approaches (Option 1 vs Option 2 vs Option 3)",
        "priority": "high",
        "estimated_effort": "medium"
      },
      {
        "feature_id": "RISK-006",
        "name": "Structured JSON Output",
        "description": "Generate machine-parseable JSON with risk scores, pros/cons, recommendations, go/no-go decision",
        "priority": "critical",
        "estimated_effort": "medium"
      },
      {
        "feature_id": "RISK-007",
        "name": "Risk Assessment Storage",
        "description": "Save assessments to coderef/risk-assessments/{feature-name}-{timestamp}.json with history tracking",
        "priority": "high",
        "estimated_effort": "small"
      },
      {
        "feature_id": "RISK-008",
        "name": "Mitigation Strategies",
        "description": "Generate actionable mitigation strategies for identified risks",
        "priority": "high",
        "estimated_effort": "medium"
      }
    ],
    "5_task_id_system": {
      "workorder": {
        "id": "WO-RISK-ASSESSMENT-001",
        "name": "Risk Assessment",
        "feature_dir": "coderef/working/risk-assessment"
      },
      "task_categories": {
        "SETUP": "Setup and configuration tasks",
        "SCHEMA": "JSON schema and data structures",
        "VALIDATE": "Input validation implementation",
        "ANALYZE": "Project context analysis",
        "SCORE": "Risk scoring algorithm",
        "COMPARE": "Multi-option comparison logic",
        "OUTPUT": "Output generation and storage",
        "HANDLER": "MCP handler integration",
        "TEST": "Testing implementation",
        "DOCS": "Documentation updates"
      },
      "tasks": [
        {
          "id": "SETUP-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Create coderef/risk-assessments/ directory",
          "category": "SETUP",
          "estimated_time": "5 min"
        },
        {
          "id": "SETUP-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Add RISK_ASSESSMENTS_DIR to constants.py",
          "category": "SETUP",
          "estimated_time": "5 min"
        },
        {
          "id": "SCHEMA-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Design RiskAssessment JSON schema structure",
          "category": "SCHEMA",
          "estimated_time": "30 min"
        },
        {
          "id": "SCHEMA-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Create templates/risk/assessment-schema.json",
          "category": "SCHEMA",
          "estimated_time": "20 min"
        },
        {
          "id": "SCHEMA-003",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Add RiskAssessment TypedDict to type_defs.py",
          "category": "SCHEMA",
          "estimated_time": "15 min"
        },
        {
          "id": "VALIDATE-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Add validate_risk_inputs() to validation.py",
          "category": "VALIDATE",
          "estimated_time": "30 min"
        },
        {
          "id": "ANALYZE-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Create RiskGenerator class in generators/risk_generator.py",
          "category": "ANALYZE",
          "estimated_time": "1 hour"
        },
        {
          "id": "ANALYZE-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement analyze_project_context() method",
          "category": "ANALYZE",
          "estimated_time": "1.5 hours"
        },
        {
          "id": "SCORE-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Design risk scoring matrix (severity x likelihood)",
          "category": "SCORE",
          "estimated_time": "45 min"
        },
        {
          "id": "SCORE-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement evaluate_breaking_changes() dimension",
          "category": "SCORE",
          "estimated_time": "1 hour"
        },
        {
          "id": "SCORE-003",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement evaluate_security_risks() dimension",
          "category": "SCORE",
          "estimated_time": "1 hour"
        },
        {
          "id": "SCORE-004",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement evaluate_performance_impact() dimension",
          "category": "SCORE",
          "estimated_time": "45 min"
        },
        {
          "id": "SCORE-005",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement evaluate_maintainability() dimension",
          "category": "SCORE",
          "estimated_time": "45 min"
        },
        {
          "id": "SCORE-006",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement evaluate_reversibility() dimension",
          "category": "SCORE",
          "estimated_time": "30 min"
        },
        {
          "id": "SCORE-007",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement calculate_composite_score() method",
          "category": "SCORE",
          "estimated_time": "30 min"
        },
        {
          "id": "COMPARE-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement compare_options() for multi-option analysis",
          "category": "COMPARE",
          "estimated_time": "1 hour"
        },
        {
          "id": "OUTPUT-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement generate_assessment_json() output method",
          "category": "OUTPUT",
          "estimated_time": "45 min"
        },
        {
          "id": "OUTPUT-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement generate_recommendations() method",
          "category": "OUTPUT",
          "estimated_time": "45 min"
        },
        {
          "id": "OUTPUT-003",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Implement save_assessment() with timestamp",
          "category": "OUTPUT",
          "estimated_time": "30 min"
        },
        {
          "id": "HANDLER-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Add handle_assess_risk() to tool_handlers.py",
          "category": "HANDLER",
          "estimated_time": "30 min"
        },
        {
          "id": "HANDLER-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Apply @mcp_error_handler decorator",
          "category": "HANDLER",
          "estimated_time": "10 min"
        },
        {
          "id": "HANDLER-003",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Register assess_risk tool in server.py TOOLS list",
          "category": "HANDLER",
          "estimated_time": "15 min"
        },
        {
          "id": "TEST-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Write unit tests for validate_risk_inputs()",
          "category": "TEST",
          "estimated_time": "30 min"
        },
        {
          "id": "TEST-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Write unit tests for RiskGenerator.analyze_project_context()",
          "category": "TEST",
          "estimated_time": "45 min"
        },
        {
          "id": "TEST-003",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Write unit tests for all 5 risk dimension evaluators",
          "category": "TEST",
          "estimated_time": "1.5 hours"
        },
        {
          "id": "TEST-004",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Write unit tests for calculate_composite_score()",
          "category": "TEST",
          "estimated_time": "30 min"
        },
        {
          "id": "TEST-005",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Write integration test for full risk assessment workflow",
          "category": "TEST",
          "estimated_time": "1 hour"
        },
        {
          "id": "TEST-006",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Write multi-option comparison test",
          "category": "TEST",
          "estimated_time": "45 min"
        },
        {
          "id": "DOCS-001",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Update CLAUDE.md with assess_risk tool documentation",
          "category": "DOCS",
          "estimated_time": "30 min"
        },
        {
          "id": "DOCS-002",
          "workorder_id": "WO-RISK-ASSESSMENT-001",
          "description": "Update USER-GUIDE.md with usage examples",
          "category": "DOCS",
          "estimated_time": "30 min"
        }
      ]
    },
    "6_implementation_phases": {
      "phase_1_foundation": {
        "name": "Foundation and Schema Design",
        "objective": "Set up infrastructure, design data structures, implement validation",
        "tasks": [
          "SETUP-001",
          "SETUP-002",
          "SCHEMA-001",
          "SCHEMA-002",
          "SCHEMA-003",
          "VALIDATE-001"
        ],
        "deliverables": [
          "coderef/risk-assessments/ directory created",
          "RiskAssessment JSON schema designed",
          "RiskAssessment TypedDict defined",
          "Input validation implemented"
        ],
        "estimated_duration": "4-6 hours"
      },
      "phase_2_risk_evaluation": {
        "name": "Risk Evaluation Engine",
        "objective": "Implement core risk scoring algorithm and all 5 dimensions",
        "tasks": [
          "ANALYZE-001",
          "ANALYZE-002",
          "SCORE-001",
          "SCORE-002",
          "SCORE-003",
          "SCORE-004",
          "SCORE-005",
          "SCORE-006",
          "SCORE-007"
        ],
        "deliverables": [
          "RiskGenerator class created",
          "Project context analysis working",
          "All 5 risk dimensions implemented",
          "Composite scoring algorithm complete",
          "Deterministic and explainable results"
        ],
        "estimated_duration": "2-3 days"
      },
      "phase_3_comparison_and_output": {
        "name": "Multi-Option Comparison and Output Generation",
        "objective": "Implement option comparison, generate structured output, save assessments",
        "tasks": [
          "COMPARE-001",
          "OUTPUT-001",
          "OUTPUT-002",
          "OUTPUT-003",
          "HANDLER-001",
          "HANDLER-002",
          "HANDLER-003"
        ],
        "deliverables": [
          "Multi-option comparison working",
          "JSON output generation complete",
          "Recommendations and mitigation strategies",
          "Assessment storage with history",
          "MCP handler integrated"
        ],
        "estimated_duration": "1-2 days"
      },
      "phase_4_testing_and_docs": {
        "name": "Testing, Documentation, and Polish",
        "objective": "Complete test coverage, update documentation, performance optimization",
        "tasks": [
          "TEST-001",
          "TEST-002",
          "TEST-003",
          "TEST-004",
          "TEST-005",
          "TEST-006",
          "DOCS-001",
          "DOCS-002"
        ],
        "deliverables": [
          "Unit tests for all components",
          "Integration tests passing",
          "Performance under 5 seconds verified",
          "CLAUDE.md updated",
          "USER-GUIDE.md updated"
        ],
        "estimated_duration": "1-2 days"
      }
    },
    "7_testing_strategy": {
      "unit_tests": [
        "validate_risk_inputs() - Test all validation paths",
        "analyze_project_context() - Test with various project structures",
        "evaluate_breaking_changes() - Test detection accuracy",
        "evaluate_security_risks() - Test security pattern detection",
        "evaluate_performance_impact() - Test performance heuristics",
        "evaluate_maintainability() - Test complexity metrics",
        "evaluate_reversibility() - Test rollback analysis",
        "calculate_composite_score() - Test scoring math",
        "compare_options() - Test multi-option logic",
        "generate_recommendations() - Test output quality"
      ],
      "integration_tests": [
        "Full risk assessment workflow - Single option",
        "Full risk assessment workflow - Multi-option comparison",
        "Missing context graceful degradation",
        "Performance test (< 5 seconds)",
        "JSON schema validation",
        "Assessment storage and retrieval"
      ],
      "edge_cases": [
        "Empty project (no files)",
        "Missing proposed changes",
        "Invalid file paths",
        "Extremely large projects (performance)",
        "5+ options (limit testing)",
        "Corrupted context data"
      ],
      "performance_requirements": [
        "Single-option assessment: < 3 seconds",
        "3-option comparison: < 5 seconds",
        "Memory usage: < 100MB",
        "No blocking I/O operations"
      ]
    },
    "8_success_criteria": {
      "functional_requirements": [
        "Tool evaluates single proposed change and returns risk JSON within 5 seconds",
        "Tool compares up to 5 alternative approaches with relative risk scores",
        "Risk dimensions cover all 5 categories (breaking, security, performance, maintainability, reversibility)",
        "Recommendations include clear go/no-go guidance based on configurable threshold",
        "Saved assessments are valid JSON and machine-parseable",
        "Tool handles missing files/context gracefully with partial assessment",
        "Risk scoring is deterministic (same input = same output)",
        "Mitigation strategies generated for all identified risks"
      ],
      "quality_requirements": [
        "All unit tests passing (100% coverage for scoring logic)",
        "All integration tests passing",
        "Performance under 5 seconds for typical projects",
        "JSON schema validation enforced",
        "Error messages are clear and actionable",
        "Code follows existing MCP patterns (decorators, validation, errors)"
      ],
      "documentation_requirements": [
        "CLAUDE.md updated with tool documentation",
        "USER-GUIDE.md updated with usage examples",
        "Risk scoring algorithm documented and explainable",
        "JSON schema documented with examples"
      ],
      "acceptance_criteria": [
        "AI agent can call tool and parse results programmatically",
        "Tool correctly identifies 80%+ of high-risk changes in test scenarios",
        "Multi-option comparison provides clear winner recommendation",
        "Tool never crashes on malformed input (validation catches all errors)",
        "Assessments are stored and retrievable for history tracking"
      ]
    },
    "9_implementation_checklist": {
      "phase_1_foundation": [
        "☐ SETUP-001: Create coderef/risk-assessments/ directory",
        "☐ SETUP-002: Add RISK_ASSESSMENTS_DIR to constants.py",
        "☐ SCHEMA-001: Design RiskAssessment JSON schema structure",
        "☐ SCHEMA-002: Create templates/risk/assessment-schema.json",
        "☐ SCHEMA-003: Add RiskAssessment TypedDict to type_defs.py",
        "☐ VALIDATE-001: Add validate_risk_inputs() to validation.py"
      ],
      "phase_2_risk_evaluation": [
        "☐ ANALYZE-001: Create RiskGenerator class in generators/risk_generator.py",
        "☐ ANALYZE-002: Implement analyze_project_context() method",
        "☐ SCORE-001: Design risk scoring matrix (severity x likelihood)",
        "☐ SCORE-002: Implement evaluate_breaking_changes() dimension",
        "☐ SCORE-003: Implement evaluate_security_risks() dimension",
        "☐ SCORE-004: Implement evaluate_performance_impact() dimension",
        "☐ SCORE-005: Implement evaluate_maintainability() dimension",
        "☐ SCORE-006: Implement evaluate_reversibility() dimension",
        "☐ SCORE-007: Implement calculate_composite_score() method"
      ],
      "phase_3_comparison_and_output": [
        "☐ COMPARE-001: Implement compare_options() for multi-option analysis",
        "☐ OUTPUT-001: Implement generate_assessment_json() output method",
        "☐ OUTPUT-002: Implement generate_recommendations() method",
        "☐ OUTPUT-003: Implement save_assessment() with timestamp",
        "☐ HANDLER-001: Add handle_assess_risk() to tool_handlers.py",
        "☐ HANDLER-002: Apply @mcp_error_handler decorator",
        "☐ HANDLER-003: Register assess_risk tool in server.py TOOLS list"
      ],
      "phase_4_testing_and_docs": [
        "☐ TEST-001: Write unit tests for validate_risk_inputs()",
        "☐ TEST-002: Write unit tests for RiskGenerator.analyze_project_context()",
        "☐ TEST-003: Write unit tests for all 5 risk dimension evaluators",
        "☐ TEST-004: Write unit tests for calculate_composite_score()",
        "☐ TEST-005: Write integration test for full risk assessment workflow",
        "☐ TEST-006: Write multi-option comparison test",
        "☐ DOCS-001: Update CLAUDE.md with assess_risk tool documentation",
        "☐ DOCS-002: Update USER-GUIDE.md with usage examples"
      ]
    }
  }
}
