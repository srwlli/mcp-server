# PLANNING-ANALYZER.md - planning_analyzer.py Authoritative Reference

**File:** `generators/planning_analyzer.py`
**Category:** Planning & Analysis Engine
**Lines:** 919
**Version:** 1.3.0 (v1.3.0 - .coderef/ integration)
**Status:** ✅ Production
**Generated:** 2026-01-02
**Workorder:** WO-RESOURCE-SHEET-P0-001

---

## 1. Purpose & Scope

**What It Does:**
`planning_analyzer.py` is the project analysis engine for coderef-workflow. It automates Section 0 (Preparation) of implementation plans by scanning projects to discover foundation docs, coding standards, reference components, and patterns.

**Key Innovation (v1.3.0):**
Integrated with .coderef/ pre-scanned structure for **5-10x faster planning**. Reads `.coderef/index.json`, `.coderef/reports/patterns.json`, and `.coderef/reports/coverage.json` instead of live scanning.

**What It Returns:**
`PreparationSummaryDict` - Complete analysis results used by `PlanningGenerator` to populate Section 0 of `plan.json`.

**Dependencies:**
- **coderef-context MCP server** (optional) - Calls `coderef_scan`, `coderef_patterns`, `coderef_coverage` tools
- **.coderef/ structure** (preferred) - Reads pre-scanned data from `.coderef/` directory
- **mcp_client.py** - Async client for MCP tool calls
- **type_defs.py** - `PreparationSummaryDict` type definition
- **constants.py** - `EXCLUDE_DIRS`, `ALLOWED_FILE_EXTENSIONS`

**Core Workflow:**
```
PlanningAnalyzer.analyze()
├─ 1. Check .coderef/ freshness (drift.json >10% warns)
├─ 2. Scan foundation docs (README, ARCHITECTURE, etc.)
├─ 3. Read foundation doc content (extract headers, preview)
├─ 4. Read inventory data (.coderef/index.json → MCP → filesystem)
├─ 5. Scan coding standards (BEHAVIOR-STANDARDS.md, etc.)
├─ 6. Find reference components (similar files/patterns)
├─ 7. Identify patterns (.coderef/reports/patterns.json → MCP → regex)
├─ 8. Detect technology stack (package.json, requirements.txt)
├─ 9. Analyze project structure (directory organization)
└─ 10. Identify gaps and risks (.coderef/reports/coverage.json → analysis)
```

**Performance:**
- **With .coderef/:** 5-10 seconds (reads pre-scanned data)
- **Without .coderef/:** 30-60 seconds (live filesystem scanning + MCP tool calls)

---

## 2. State Ownership & Source of Truth (Canonical)

| State | Owner | Type | Persistence | Source of Truth |
|-------|-------|------|-------------|-----------------|
| **project_path** | PlanningAnalyzer instance | Path | Constructor argument | `self.project_path = project_path` |
| **Analysis results** | PlanningAnalyzer.analyze() | PreparationSummaryDict | Return value (ephemeral) | Computed on-demand, not cached |
| **.coderef/ data** | External (coderef-context) | JSON files | Disk (`.coderef/` directory) | Generated by `coderef scan` command |
| **Foundation docs** | Project root or coderef/foundation-docs/ | Markdown files | Disk | Project files |
| **Coding standards** | coderef/standards/ | Markdown files | Disk | Project files |

**Key Insight:** PlanningAnalyzer is **stateless** - it owns only `project_path`. All analysis data is computed fresh on each `analyze()` call. No caching, no persistent state.

---

## 3. Architecture & Data Flow

### Class Structure

```
PlanningAnalyzer
├─ __init__(project_path: Path)
├─ analyze() → PreparationSummaryDict (async, orchestrates 9 sub-methods)
├─ check_coderef_freshness() → str | None (warns if >10% drift)
├─ scan_foundation_docs() → dict (available/missing lists)
├─ read_foundation_doc_content() → dict (extract headers, previews)
├─ read_inventory_data() → dict (async, 3-tier fallback)
├─ scan_coding_standards() → dict (available/missing lists)
├─ find_reference_components() → list (async, similar files)
├─ identify_patterns() → list (async, 2-tier fallback)
├─ detect_technology_stack() → dict (language, framework, etc.)
├─ analyze_project_structure() → dict (organization pattern)
├─ identify_gaps_and_risks() → list (async, missing docs/tests/CI)
└─ _scan_source_files() → list[Path] (helper, respects EXCLUDE_DIRS)
```

### 3-Tier Fallback System (v1.3.0)

**Priority 1: Read .coderef/ pre-scanned data** (fastest, 5-10x speedup)
```python
# read_inventory_data(), identify_patterns(), identify_gaps_and_risks()
if check_coderef_available(project_path, 'index.json'):
    data = read_coderef_output(project_path, 'index.json')
    # Use pre-scanned data
```

**Priority 2: Call coderef-context MCP tools** (medium speed, live scan)
```python
result = await call_coderef_tool('coderef_scan', {'project_path': str(project_path)})
# Returns fresh scan results
```

**Priority 3: Regex-based filesystem analysis** (slowest, fallback)
```python
source_files = self._scan_source_files()
# Manual pattern matching with regex
```

### Freshness Check (v1.3.0)

```python
def check_coderef_freshness() -> str | None:
    drift_data = read_coderef_output(project_path, 'reports/drift.json')
    drift_percent = (changed_files / total_files) * 100

    if drift_percent > 10:
        return "⚠️ .coderef/ data is stale (X% drift), re-run coderef scan"
```

**Lifecycle:**
1. Called at start of `analyze()`
2. Warns user if drift >10%
3. Analysis continues (doesn't block, user decision to re-scan)

---

## 4. Method Catalog & Contracts

### 4.1 Constructor

```python
def __init__(self, project_path: Path)
```

**Args:**
- `project_path` (Path): Absolute path to project directory

**Side Effects:**
- Sets `self.project_path`
- Logs initialization

**Performance:** <1ms

---

### 4.2 Main Analysis Method

```python
async def analyze(self) -> PreparationSummaryDict
```

**Purpose:** Orchestrates all analysis operations, returns complete preparation summary

**Workflow:**
1. Check .coderef/ freshness (warn if stale)
2. Scan foundation docs (README, ARCHITECTURE, etc.)
3. Read foundation doc content (extract headers, preview)
4. Read inventory data (3-tier fallback)
5. Scan coding standards (BEHAVIOR-STANDARDS.md, etc.)
6. Find reference components (similar files)
7. Identify patterns (3-tier fallback)
8. Detect technology stack (package.json, requirements.txt)
9. Analyze project structure (directory organization)
10. Identify gaps and risks (missing docs/tests/CI)

**Returns:** `PreparationSummaryDict` with 9 keys:
```python
{
    'foundation_docs': {'available': [...], 'missing': [...]},
    'foundation_doc_content': {'ARCHITECTURE.md': {...}, ...},
    'inventory_data': {'endpoints': [...], 'schemas': [...], ...},
    'coding_standards': {'available': [...], 'missing': [...]},
    'reference_components': ['file1.py', 'file2.py', ...],
    'key_patterns_identified': ['Pattern 1', 'Pattern 2', ...],
    'technology_stack': {'language': '...', 'framework': '...', ...},
    'project_structure': {'pattern': '...', 'depth': N, ...},
    'gaps_and_risks': ['Gap 1', 'Gap 2', ...]
}
```

**Performance:**
- With .coderef/: 5-10 seconds
- Without .coderef/: 30-60 seconds

**Async:** Yes (uses `await` for MCP tool calls)

---

### 4.3 Freshness Check

```python
def check_coderef_freshness(self) -> str | None
```

**Purpose:** Checks if .coderef/ data is stale by reading `drift.json`

**Returns:**
- `str`: Warning message if >10% drift detected
- `None`: If fresh or missing drift data

**Logic:**
```python
drift_percent = (len(changed_files) / total_files) * 100
if drift_percent > 10:
    return "⚠️ .coderef/ data is stale (X% drift), re-run coderef scan"
```

**Performance:** <5ms (single file read)

**Added:** v1.3.0 (WO-CODEREF-INTEGRATION-001)

---

### 4.4 Foundation Docs Scanner

```python
def scan_foundation_docs(self) -> dict
```

**Purpose:** Scans for foundation documentation files

**Checks For:**
- README.md
- API.md
- ARCHITECTURE.md
- COMPONENTS.md
- SCHEMA.md
- USER-GUIDE.md

**Search Locations:**
1. Project root (`project_path/`)
2. `coderef/foundation-docs/`

**Returns:**
```python
{
    'available': ['README.md (root)', 'ARCHITECTURE.md (coderef/foundation-docs)', ...],
    'missing': ['API.md', 'COMPONENTS.md', ...]
}
```

**Performance:** ~10ms (checks 12 file paths)

---

### 4.5 Foundation Doc Content Reader

```python
def read_foundation_doc_content(self) -> dict
```

**Purpose:** Reads and extracts key content from foundation docs

**Reads:** ARCHITECTURE.md, API.md, COMPONENTS.md, SCHEMA.md, README.md

**Extracts:**
- Location (root or coderef/foundation-docs)
- Preview (first 500 characters)
- Headers (first 10 markdown headers via `_extract_headers()`)
- Size (character count)

**Returns:**
```python
{
    'ARCHITECTURE.md': {
        'location': 'root',
        'preview': '# Architecture\n\nThis project...',
        'headers': ['Architecture', 'Overview', 'Components', ...],
        'size': 15234
    },
    ...
}
```

**Performance:** ~50-100ms (reads 5 files, each ~10-50KB)

**Helper:** `_extract_headers(content: str) -> List[str]`
- Uses regex: `r'^#{1,3}\s+(.+)$'`
- Returns first 10 headers

---

### 4.6 Inventory Data Reader (3-Tier Fallback)

```python
async def read_inventory_data(self) -> dict
```

**Purpose:** Read existing inventory data from `.coderef/index.json` or generate live inventory

**Priority Order:**
1. **.coderef/index.json** (fastest - pre-scanned data)
2. **MCP tool call** (`coderef_scan` - live scan)
3. **Filesystem scan** (fallback - manual analysis)

**Implementation:**
```python
# Tier 1: Read .coderef/index.json
if check_coderef_available(project_path, 'index.json'):
    data = read_coderef_output(project_path, 'index.json')
    return {'endpoints': [...], 'schemas': [...], ...}

# Tier 2: Call MCP tool
try:
    result = await call_coderef_tool('coderef_scan', {...})
    return result.get('data', {})
except:
    pass

# Tier 3: Filesystem scan
return {'endpoints': [], 'schemas': [], 'dependencies': [], ...}
```

**Returns:**
```python
{
    'endpoints': ['GET /api/users', 'POST /api/auth', ...],
    'schemas': ['User', 'AuthToken', ...],
    'dependencies': ['fastapi', 'pydantic', ...]
}
```

**Performance:**
- Tier 1: ~5ms (file read)
- Tier 2: ~500ms (MCP call)
- Tier 3: ~2-5s (filesystem scan)

**Async:** Yes (Tier 2 uses MCP client)

---

### 4.7 Coding Standards Scanner

```python
def scan_coding_standards(self) -> dict
```

**Purpose:** Scans for coding standards documentation

**Checks For:**
- UI-PATTERNS.md
- BEHAVIOR-PATTERNS.md
- UX-PATTERNS.md
- CODING-STANDARDS.md

**Search Location:** `coderef/standards/`

**Returns:**
```python
{
    'available': ['UI-PATTERNS.md', 'BEHAVIOR-PATTERNS.md', ...],
    'missing': ['UX-PATTERNS.md', 'CODING-STANDARDS.md', ...]
}
```

**Performance:** ~5ms (checks 4 file paths)

---

### 4.8 Reference Components Finder

```python
async def find_reference_components(self) -> list
```

**Purpose:** Finds similar files/patterns to use as implementation references

**Strategy:**
- Scans source files
- Identifies most common file types
- Returns list of representative files

**Returns:**
```python
['src/auth/login.py', 'src/api/users.py', 'src/utils/validation.py', ...]
```

**Performance:** ~1-2s (scans all source files)

**Async:** Yes (future enhancement for MCP integration)

---

### 4.9 Pattern Identifier (2-Tier Fallback)

```python
async def identify_patterns(self) -> list
```

**Purpose:** Identifies coding patterns from `.coderef/reports/patterns.json` or regex analysis

**Priority Order:**
1. **.coderef/reports/patterns.json** (fastest)
2. **MCP tool call** (`coderef_patterns`)
3. **Regex analysis** (fallback)

**Tier 1 Implementation:**
```python
if check_coderef_available(project_path, 'reports/patterns.json'):
    patterns_data = read_coderef_output(project_path, 'reports/patterns.json')
    return [p['pattern'] for p in patterns_data['patterns'][:15]]
```

**Tier 2 Implementation:**
```python
result = await call_coderef_tool('coderef_patterns', {'project_path': str(project_path)})
return [str(p) for p in result.get('patterns', [])[:15]]
```

**Tier 3 Implementation (Regex Fallback):**
Scans first 200 source files for:
- Error handling: `try-catch`, `throw new Error`
- File organization: `export from`
- Naming conventions: camelCase functions, UPPER_SNAKE constants

**Returns:**
```python
[
    'Error handling: try-catch blocks found in 45 files',
    'Naming: camelCase for functions (120/150 functions)',
    'File organization: barrel exports found in 30 files',
    ...
]
```

**Performance:**
- Tier 1: ~5ms
- Tier 2: ~500ms
- Tier 3: ~2-5s

**Async:** Yes (Tier 2)

**Added:** v1.3.0 integration with .coderef/

---

### 4.10 Technology Stack Detector

```python
def detect_technology_stack(self) -> dict
```

**Purpose:** Identifies technology stack from indicator files

**Checks For:**
- **package.json** → Node.js/TypeScript (reads dependencies)
- **requirements.txt** → Python (parses packages)
- **pyproject.toml** → Python (reads tool.poetry.dependencies)
- **go.mod** → Go
- **Cargo.toml** → Rust

**Extracts:**
- Language (JavaScript, TypeScript, Python, Go, Rust)
- Framework (React, Next.js, FastAPI, Flask, etc.)
- Database (PostgreSQL, MongoDB, SQLite, etc.)
- Testing (Jest, pytest, vitest, etc.)
- Build system (Webpack, Vite, tsc, etc.)

**Returns:**
```python
{
    'language': 'Python',
    'framework': 'FastAPI',
    'database': 'PostgreSQL',
    'testing': 'pytest',
    'build': 'uv'
}
```

**Performance:** ~50-100ms (reads 1-2 files, parses JSON/TOML)

---

### 4.11 Project Structure Analyzer

```python
def analyze_project_structure(self) -> dict
```

**Purpose:** Analyzes directory organization pattern

**Detects:**
- **Monorepo** (has `packages/` or `apps/`)
- **Feature-based** (has `features/` directory)
- **Domain-driven** (has `domain/` directory)
- **Layered** (has `controllers/`, `services/`, `models/`)
- **Flat** (all files in root or single directory)

**Returns:**
```python
{
    'pattern': 'layered',  # or 'monorepo', 'feature-based', etc.
    'depth': 4,  # max directory nesting
    'top_level_dirs': ['src', 'tests', 'docs', 'scripts']
}
```

**Performance:** ~20-50ms (scans top 2 directory levels)

---

### 4.12 Gaps & Risks Identifier (2-Tier Fallback)

```python
async def identify_gaps_and_risks(self) -> list
```

**Purpose:** Identifies missing documentation, test coverage, CI/CD

**Priority Order:**
1. **.coderef/reports/coverage.json** (fastest)
2. **MCP tool call** (`coderef_coverage`)
3. **Manual analysis** (fallback)

**Tier 1 Implementation:**
```python
if check_coderef_available(project_path, 'reports/coverage.json'):
    coverage_data = read_coderef_output(project_path, 'reports/coverage.json')
    if coverage_data.get('coverage_percent', 100) < 70:
        gaps.append(f"Low test coverage ({coverage_percent}%)")
```

**Checks:**
- Test coverage <70%
- Missing foundation docs (README, ARCHITECTURE, etc.)
- Missing coding standards (UI-PATTERNS.md, etc.)
- No CI/CD configuration (.github/workflows/, .gitlab-ci.yml)
- No .gitignore file
- No type checking (tsconfig.json, mypy.ini)

**Returns:**
```python
[
    'Low test coverage (45% coverage)',
    'Missing foundation docs: API.md, COMPONENTS.md',
    'Missing coding standards: UI-PATTERNS.md',
    'No CI/CD configuration detected',
    'No type checking configuration found'
]
```

**Performance:**
- Tier 1: ~5ms
- Tier 2: ~500ms
- Tier 3: ~100ms

**Async:** Yes (Tier 2)

**Added:** v1.3.0 integration with .coderef/

---

### 4.13 Source Files Scanner (Helper)

```python
def _scan_source_files(self) -> list[Path]
```

**Purpose:** Recursively scans for source files, respects `EXCLUDE_DIRS`

**Excluded Directories:**
- node_modules
- .git
- __pycache__
- dist, build
- .venv, venv

**Allowed Extensions:** `.py`, `.js`, `.ts`, `.jsx`, `.tsx`, `.go`, `.rs`

**Returns:** List of Path objects

**Performance:** ~500ms-2s (depends on project size)

---

## 5. Integration Points

### 5.1 With coderef-context MCP Server

**Tools Used:**
- `coderef_scan` - Live code scanning (fallback if .coderef/ missing)
- `coderef_patterns` - Code pattern detection (fallback)
- `coderef_coverage` - Test coverage analysis (fallback)

**Client:** Uses `mcp_client.call_coderef_tool(tool_name, arguments)`

**Async:** All MCP calls are async (`await call_coderef_tool(...)`)

---

### 5.2 With .coderef/ Structure (v1.3.0)

**Files Read:**
- `.coderef/index.json` - Code inventory (functions, classes, components)
- `.coderef/reports/patterns.json` - Detected code patterns
- `.coderef/reports/coverage.json` - Test coverage metrics
- `.coderef/reports/drift.json` - Freshness tracking

**Utilities:**
- `check_coderef_available(project_path, filename)` - Checks if file exists
- `read_coderef_output(project_path, filename)` - Reads and parses JSON

**Performance Gain:** 5-10x faster than live scanning

---

### 5.3 With PlanningGenerator

**Output Usage:**
PlanningGenerator receives `PreparationSummaryDict` from `PlanningAnalyzer.analyze()` and uses it to populate Section 0 of `plan.json`.

**Data Flow:**
```
PlanningAnalyzer.analyze()
    ↓ (returns PreparationSummaryDict)
PlanningGenerator.generate_plan(context, analysis)
    ↓ (uses analysis data)
plan.json Section 0 (Preparation)
```

---

## 6. Performance Characteristics

### Timing Breakdown (with .coderef/)

| Operation | Time | Bottleneck |
|-----------|------|------------|
| check_coderef_freshness() | <5ms | File I/O |
| scan_foundation_docs() | ~10ms | File exists checks |
| read_foundation_doc_content() | ~50-100ms | File reads |
| read_inventory_data() (.coderef/) | ~5ms | File read |
| scan_coding_standards() | ~5ms | File exists checks |
| find_reference_components() | ~1-2s | Filesystem scan |
| identify_patterns() (.coderef/) | ~5ms | File read |
| detect_technology_stack() | ~50-100ms | File reads + parsing |
| analyze_project_structure() | ~20-50ms | Directory scanning |
| identify_gaps_and_risks() (.coderef/) | ~5ms | File read |
| **Total (with .coderef/)** | **~5-10s** | reference_components scan |

### Timing Breakdown (without .coderef/)

| Operation | Time | Bottleneck |
|-----------|------|------------|
| read_inventory_data() (MCP) | ~500ms | MCP call |
| identify_patterns() (MCP) | ~500ms | MCP call |
| identify_gaps_and_risks() (MCP) | ~500ms | MCP call |
| Other operations | ~5-10s | Same as above |
| **Total (without .coderef/)** | **~30-60s** | MCP calls + filesystem |

### Optimization Opportunities

1. **Parallel MCP calls** - Run `coderef_scan`, `coderef_patterns`, `coderef_coverage` concurrently
2. **Cache results** - Store `PreparationSummaryDict` in `analysis.json` for reuse
3. **Limit file scanning** - Already limits to first 200 files for pattern analysis
4. **Pre-generate .coderef/** - Run `coderef scan` before planning workflow

---

## 7. Error Handling & Recovery

### Error Scenarios

1. **.coderef/ missing** → Falls back to MCP tools
2. **MCP tools unavailable** → Falls back to regex analysis
3. **Foundation docs missing** → Returns empty available list (not an error)
4. **Invalid JSON in .coderef/** → Logs error, falls back to MCP
5. **File read permission denied** → Logs warning, skips file

### Recovery Paths

```python
# Example: read_inventory_data() with 3-tier fallback
try:
    # Tier 1: .coderef/
    if check_coderef_available(project_path, 'index.json'):
        return read_coderef_output(project_path, 'index.json')
except Exception as e:
    logger.debug(f"Failed to read .coderef/index.json: {e}")

try:
    # Tier 2: MCP tool
    result = await call_coderef_tool('coderef_scan', {...})
    return result.get('data', {})
except Exception as e:
    logger.debug(f"coderef_scan unavailable: {e}")

# Tier 3: Fallback
return {'endpoints': [], 'schemas': [], 'dependencies': []}
```

---

## 8. Common Pitfalls & Gotchas

### Pitfall 1: Stale .coderef/ Data
**Problem:** .coderef/ data is outdated, analysis uses old patterns
**Detection:** `check_coderef_freshness()` warns if >10% drift
**Solution:** User must re-run `coderef scan` before planning

### Pitfall 2: Large Codebases Slow Down Regex Fallback
**Problem:** Pattern analysis scans all files, takes 10+ seconds
**Mitigation:** Limits to first 200 files
**Solution:** Use .coderef/ pre-scanned data (5-10x faster)

### Pitfall 3: MCP Client Not Available
**Problem:** `call_coderef_tool()` fails if coderef-context server not running
**Detection:** Try-except catches connection errors
**Recovery:** Falls back to regex analysis

### Pitfall 4: Missing Foundation Docs
**Problem:** User expects docs to exist, but `missing` list is long
**Not an Error:** This is expected for new projects
**Action:** PlanningGenerator uses `missing` list to recommend doc creation

### Pitfall 5: Async Method Called Without await
**Problem:** `analysis = analyzer.analyze()` returns coroutine, not dict
**Symptom:** TypeError when accessing dict keys
**Fix:** `analysis = await analyzer.analyze()`

---

## 9. Testing Strategy

### Unit Tests
- Test each scanner method independently
- Mock file system with `pytest.monkeypatch`
- Test 3-tier fallback logic (Tier 1 success, Tier 1 fail → Tier 2, etc.)

### Integration Tests
- Test with real .coderef/ structure
- Test with real MCP server running
- Test with no .coderef/ and no MCP (pure fallback)

### Performance Tests
- Benchmark with .coderef/ vs without
- Verify <10s with .coderef/, <60s without
- Test large codebases (1000+ files)

---

## 10. Version History

### v1.3.0 (2026-01-02) - .coderef/ Integration
- ✅ Added `check_coderef_freshness()` with >10% drift warning
- ✅ Enhanced `read_inventory_data()` with 3-tier fallback (.coderef/ → MCP → filesystem)
- ✅ Enhanced `identify_patterns()` with 2-tier fallback (.coderef/ → MCP → regex)
- ✅ Enhanced `identify_gaps_and_risks()` with 2-tier fallback (.coderef/ → MCP → manual)
- ✅ Added `check_coderef_available()` and `read_coderef_output()` utilities
- ✅ 5-10x performance improvement with .coderef/ pre-scanned data

### v1.2.0 - MCP Integration
- ✅ Async support for MCP tool calls
- ✅ Integration with coderef-context server
- ✅ Fallback to regex analysis if MCP unavailable

### v1.0.0 - Initial Release
- ✅ Foundation docs scanning
- ✅ Coding standards detection
- ✅ Technology stack identification
- ✅ Pattern analysis (regex-based)

---

## 11. Usage Examples

### Example 1: Basic Usage

```python
from pathlib import Path
from generators.planning_analyzer import PlanningAnalyzer

analyzer = PlanningAnalyzer(Path("/path/to/project"))
analysis = await analyzer.analyze()

print(analysis['foundation_docs'])
# {'available': ['README.md (root)', ...], 'missing': ['API.md', ...]}

print(analysis['technology_stack'])
# {'language': 'Python', 'framework': 'FastAPI', ...}
```

### Example 2: Check Freshness First

```python
analyzer = PlanningAnalyzer(project_path)
warning = analyzer.check_coderef_freshness()

if warning:
    print(warning)
    # ⚠️ .coderef/ data is stale (15.3% drift), re-run coderef scan
    # User should run: coderef scan /path/to/project

analysis = await analyzer.analyze()
```

### Example 3: Used by PlanningGenerator

```python
# In PlanningGenerator.generate_plan()
analyzer = PlanningAnalyzer(project_path)
analysis = await analyzer.analyze()

# Use analysis to populate plan.json Section 0
plan['0_PREPARATION'] = {
    'foundation_docs': analysis['foundation_docs'],
    'coding_standards': analysis['coding_standards'],
    'technology_stack': analysis['technology_stack'],
    ...
}
```

---

## 12. Related Files

- **generators/planning_generator.py** - Uses `PreparationSummaryDict` to populate plan.json
- **type_defs.py** - Defines `PreparationSummaryDict` type
- **mcp_client.py** - Async client for coderef-context MCP tools
- **constants.py** - `EXCLUDE_DIRS`, `ALLOWED_FILE_EXTENSIONS`
- **coderef/utils/** - Wrapper utilities for .coderef/ access
- **.coderef/index.json** - Pre-scanned code inventory
- **.coderef/reports/patterns.json** - Pre-scanned code patterns
- **.coderef/reports/coverage.json** - Pre-scanned test coverage
- **.coderef/reports/drift.json** - Freshness tracking

---

**Generated by:** Resource Sheet MCP Tool v1.0
**Workorder:** WO-RESOURCE-SHEET-P0-001
**Task:** SHEET-003
**Timestamp:** 2026-01-02
