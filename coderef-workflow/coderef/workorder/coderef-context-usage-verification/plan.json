{
  "META_DOCUMENTATION": {
    "feature_name": "coderef-context-usage-verification",
    "workorder_id": "WO-CODEREF-CONTEXT-USAGE-VERIFICATION-001",
    "version": "1.0.0",
    "status": "planning",
    "generated_by": "PlanningGenerator",
    "has_context": true,
    "has_analysis": true,
    "uds": {
      "generated_by": "coderef-workflow v2.0.0",
      "document_type": "Implementation Plan",
      "last_updated": "2026-01-10",
      "ai_assistance": true,
      "next_review": "2026-02-09"
    }
  },
  "UNIVERSAL_PLANNING_STRUCTURE": {
    "0_preparation": {},
    "1_executive_summary": {
      "purpose": "Ensure coderef-context MCP tools, .coderef/ structure, and foundation docs are properly utilized in the planning phase workflow",
      "value_proposition": "Verify and enhance integration of code intelligence from coderef-context, pre-scanned .coderef/ data, and foundation docs throughout the planning workflow",
      "real_world_analogy": "Similar to building coderef-context-usage-verification - systematically implementing each requirement to deliver complete functionality",
      "use_case": "User requests coderef-context-usage-verification \u2192 System implements: Verify planning_analyzer.py reads .coderef/ files (index.json, patterns.json, coverage.json), Ensure foundation docs (ARCHITECTURE.md, SCHEMA.md, API.md, COMPONENTS.md) are utilized in analysis, Confirm coderef-context MCP tools are called when needed for dynamic analysis \u2192 Feature is functional",
      "output": "Implemented 5 requirements: Verify planning_analyzer.py reads .coderef/ files (index.json, patterns.json, coverage.json), Ensure foundation docs (ARCHITECTURE.md, SCHEMA.md, API.md, COMPONENTS.md) are utilized in analysis, Confirm coderef-context MCP tools are called when needed for dynamic analysis"
    },
    "2_risk_assessment": {
      "overall_risk": "medium",
      "complexity": "medium (estimated 5-15 files, 200-1000 lines)",
      "scope": "Estimated 5 requirements affecting multiple components",
      "file_system_risk": "low (standard code changes only)",
      "dependencies": [
        "Must maintain backward compatibility with existing plans",
        "No breaking changes to planning workflow API",
        "Must work with existing .coderef/ structure"
      ],
      "performance_concerns": [
        "No significant performance concerns identified - monitor during implementation"
      ],
      "security_considerations": [
        "Follow existing security patterns - review during implementation"
      ],
      "breaking_changes": "none (extending existing functionality)"
    },
    "3_current_state_analysis": {
      "affected_files": [
        "Identify during implementation based on feature scope"
      ],
      "dependencies": {
        "existing_internal": [
          "Existing modules and components - identify during implementation"
        ],
        "existing_external": [],
        "new_external": [],
        "new_internal": []
      },
      "architecture_context": "Follows existing patterns: Standard implementation patterns"
    },
    "4_key_features": {
      "primary_features": [
        "Verify planning_analyzer.py reads .coderef/ files (index.json, patterns.json, coverage.json)",
        "Ensure foundation docs (ARCHITECTURE.md, SCHEMA.md, API.md, COMPONENTS.md) are utilized in analysis",
        "Confirm coderef-context MCP tools are called when needed for dynamic analysis",
        "Validate that plans include insights from all three sources (coderef-context, .coderef/, foundation docs)",
        "Add logging to track which data sources are used during planning"
      ],
      "secondary_features": [],
      "edge_case_handling": [
        "Empty or null input validation",
        "Invalid input error handling",
        "Boundary conditions and limits"
      ],
      "configuration_options": [
        "None"
      ]
    },
    "5_task_id_system": {
      "tasks": [
        "SETUP-001: Review current planning_analyzer.py to identify where .coderef/ files are read and where MCP tools should be called",
        "VERIFY-001: Verify planning_analyzer.py reads .coderef/index.json for code inventory (line ~215 in planning_analyzer.py)",
        "VERIFY-002: Verify planning_analyzer.py reads .coderef/reports/patterns.json for coding conventions",
        "VERIFY-003: Verify planning_analyzer.py reads .coderef/reports/coverage.json for test gap analysis",
        "VERIFY-004: Verify foundation docs (ARCHITECTURE.md, SCHEMA.md, API.md, COMPONENTS.md) are parsed and included in analysis.json",
        "ENHANCE-001: Add coderef_query MCP tool call to planning_analyzer.py for dependency/relationship analysis during risk assessment",
        "ENHANCE-002: Add coderef_impact MCP tool call to planning_analyzer.py for impact analysis in risk assessment section",
        "ENHANCE-003: Add coderef_complexity MCP tool call to planning_analyzer.py for effort estimation in task generation",
        "ENHANCE-004: Add coderef_diagram MCP tool call to optionally generate architecture diagrams for complex features",
        "LOG-001: Add logging to track which data sources are used (file reads vs MCP tool calls) with telemetry",
        "TEST-001: Write unit tests for new MCP tool integration with mocked responses",
        "TEST-002: Write integration tests to verify end-to-end planning workflow uses all three sources",
        "DOC-001: Update CLAUDE.md and planning documentation to reflect MCP tool usage"
      ]
    },
    "6_implementation_phases": {
      "phases": [
        {
          "phase": 1,
          "name": "Phase 1: Discovery & Verification",
          "description": "Review current implementation and verify existing .coderef/ and foundation doc usage",
          "tasks": [
            "SETUP-001",
            "VERIFY-001",
            "VERIFY-002",
            "VERIFY-003",
            "VERIFY-004"
          ],
          "deliverables": [
            "Complete audit of current data source usage",
            "Documentation of which tools are used vs missing",
            "Gap analysis complete"
          ]
        },
        {
          "phase": 2,
          "name": "Phase 2: MCP Tool Integration",
          "description": "Add coderef_query, coderef_impact, coderef_complexity, and coderef_diagram MCP tool calls",
          "tasks": [
            "ENHANCE-001",
            "ENHANCE-002",
            "ENHANCE-003",
            "ENHANCE-004"
          ],
          "deliverables": [
            "All 4 MCP tools integrated into planning_analyzer.py",
            "Plans include dynamic code intelligence from MCP tools",
            "Risk assessment uses coderef_impact data"
          ]
        },
        {
          "phase": 3,
          "name": "Phase 3: Logging & Telemetry",
          "description": "Add comprehensive logging to track data source utilization",
          "tasks": [
            "LOG-001"
          ],
          "deliverables": [
            "Logs show which data sources are used per planning session",
            "Telemetry tracks .coderef/ file reads vs MCP tool calls"
          ]
        },
        {
          "phase": 4,
          "name": "Phase 4: Testing & Documentation",
          "description": "Comprehensive testing and documentation updates",
          "tasks": [
            "TEST-001",
            "TEST-002",
            "DOC-001"
          ],
          "deliverables": [
            "All tests passing with 80%+ coverage",
            "Integration tests verify all three data sources used",
            "Documentation updated with MCP tool usage examples"
          ]
        }
      ]
    },
    "7_testing_strategy": {
      "unit_tests": [
        "Test individual functions and methods in isolation",
        "Verify input validation and error handling",
        "Test edge cases and boundary conditions",
        "Achieve minimum 80% code coverage"
      ],
      "integration_tests": [
        "Test component interactions and data flow",
        "Verify end-to-end functionality",
        "Test integration with existing systems"
      ],
      "end_to_end_tests": [
        "Not applicable"
      ],
      "edge_case_scenarios": [
        {
          "scenario": "Empty or null input provided",
          "setup": "Call function with None or empty string",
          "expected_behavior": "Function validates input and returns appropriate error",
          "verification": "Assert error message and status code",
          "error_handling": "ValueError or ValidationError"
        },
        {
          "scenario": "Invalid input format provided",
          "setup": "Call function with malformed or incorrect data type",
          "expected_behavior": "Function validates input type and returns error",
          "verification": "Assert error message indicates invalid format",
          "error_handling": "TypeError or ValidationError"
        },
        {
          "scenario": "Boundary conditions at limits",
          "setup": "Test with minimum and maximum allowed values",
          "expected_behavior": "Function handles boundary values correctly",
          "verification": "Assert results are within expected range",
          "error_handling": "No error expected for valid boundaries"
        }
      ]
    },
    "8_success_criteria": {
      "functional_requirements": [
        {
          "requirement": "Feature implementation complete",
          "metric": "All requirements implemented",
          "target": "100% of specified requirements",
          "validation": "Manual verification against requirements list"
        },
        {
          "requirement": "Integration successful",
          "metric": "Feature works with existing system",
          "target": "No breaking changes to existing functionality",
          "validation": "Run full test suite"
        },
        {
          "requirement": "Verify planning_analyzer.py reads .coderef/ files (index.json, patterns.json, coverage.json)",
          "metric": "Functionality verified",
          "target": "Works as specified",
          "validation": "Test cases for: Verify planning_analyzer.py reads .coderef/ files (index.json, patterns.json, coverage.json)"
        },
        {
          "requirement": "Ensure foundation docs (ARCHITECTURE.md, SCHEMA.md, API.md, COMPONENTS.md) are utilized in analysis",
          "metric": "Functionality verified",
          "target": "Works as specified",
          "validation": "Test cases for: Ensure foundation docs (ARCHITECTURE.md, SCHEMA.md, API.md, COMPONENTS.md) are utilized in analysis"
        },
        {
          "requirement": "Confirm coderef-context MCP tools are called when needed for dynamic analysis",
          "metric": "Functionality verified",
          "target": "Works as specified",
          "validation": "Test cases for: Confirm coderef-context MCP tools are called when needed for dynamic analysis"
        }
      ],
      "quality_requirements": [
        {
          "requirement": "Code coverage",
          "metric": "Line coverage",
          "target": ">80%",
          "validation": "Run coverage tool"
        },
        {
          "requirement": "Code quality",
          "metric": "Linter passes",
          "target": "Zero linting errors",
          "validation": "Run linter"
        },
        {
          "requirement": "Type safety",
          "metric": "Type checker passes",
          "target": "Zero type errors",
          "validation": "Run type checker"
        }
      ],
      "performance_requirements": [
        {
          "requirement": "Response time",
          "metric": "Execution time",
          "target": "< 1 second for typical operations",
          "validation": "Performance tests"
        }
      ],
      "security_requirements": [
        {
          "requirement": "Input validation",
          "metric": "All inputs validated",
          "target": "100% validation coverage",
          "validation": "Security review"
        }
      ]
    },
    "9_implementation_checklist": {
      "pre_implementation": [
        "\u2610 Review complete plan for gaps or ambiguities",
        "\u2610 Verify all requirements are clear and testable",
        "\u2610 Set up development environment with required dependencies"
      ],
      "phase_1": [
        "\u2610 SETUP-001: Create initial project structure and setup development environment with required dependencies"
      ],
      "phase_2": [
        "\u2610 LOGIC-001: Implement core feature functionality following existing project patterns and architecture"
      ],
      "phase_3": [
        "\u2610 TEST-001: Write unit tests for all new functionality with minimum 80% code coverage",
        "\u2610 TEST-002: Write integration tests to verify end-to-end functionality and component interactions"
      ],
      "phase_4": [
        "\u2610 DOC-001: Update documentation including README, API docs, and inline code comments for all public interfaces"
      ],
      "finalization": [
        "\u2610 All tests passing (unit + integration)",
        "\u2610 Code review completed and approved",
        "\u2610 Documentation updated and complete",
        "\u2610 Changelog entry created with version bump",
        "\u2610 Final verification against success criteria"
      ]
    }
  }
}